{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d30cd0f2",
      "metadata": {
        "id": "d30cd0f2"
      },
      "source": [
        "# Evaluación de Modelos LLM en Modismos Colombianos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "00e03151",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00e03151",
        "outputId": "4a0165c5-0110-4963-e85d-203e83163556"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datos en: LLMs_Results\n",
            "Resultados en: Metrics_Results\n",
            "Modelos: ['amazon/nova-micro-v1', 'microsoft/phi-4', 'amazon/nova-lite-v1', 'cohere/command-r-08-2024', 'qwen/qwen-2.5-72b-instruct', 'google/gemma-2-27b-it', 'meta-llama/llama-3.3-70b-instruct', 'microsoft/wizardlm-2-8x22b', 'meta-llama/llama-4-maverick', 'qwen/qwen2.5-vl-32b-instruct:free', 'x-ai/grok-3-mini-beta', 'perplexity/sonar', 'mistralai/mistral-medium-3', 'mistralai/mixtral-8x7b-instruct', 'google/gemini-2.5-flash', 'meta-llama/llama-3.1-405b-instruct', 'deepseek/deepseek-chat-v3.1', 'moonshotai/kimi-k2-0905', 'openai/o4-mini-high', 'openai/gpt-4.1', 'openai/o1-mini', 'anthropic/claude-sonnet-4', 'gpt-5.1']\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Estilos para gráficos\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Modelos\n",
        "MODELS_FILE = 'LLMs_Results/models.txt'\n",
        "\n",
        "def load_models_from_file(filepath):\n",
        "    \"\"\"Carga los nombres de modelos desde un archivo de texto.\"\"\"\n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            return [line.strip() for line in f if line.strip()]\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERROR: No se encontró el archivo {filepath}\")\n",
        "        return []\n",
        "\n",
        "MODEL_NAMES = load_models_from_file(MODELS_FILE)\n",
        "\n",
        "# Directorios\n",
        "DATA_DIR = 'LLMs_Results'\n",
        "OUTPUT_DIR = 'Metrics_Results'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Datos en: {DATA_DIR}\")\n",
        "print(f\"Resultados en: {OUTPUT_DIR}\")\n",
        "print(f\"Modelos: {MODEL_NAMES}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "28bca76a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28bca76a",
        "outputId": "514f726f-7d8a-4a47-f6f7-266be7e23714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Métricas cargadas correctamente:\n",
            "  - BERTScore (BETO y SciBETO)\n",
            "  - Sentence-BERT (paraphrase-multilingual-mpnet-base-v2, stsb-xlm-r-multilingual, scibert-mean)\n",
            "  - chrF (Character n-gram F-score)\n"
          ]
        }
      ],
      "source": [
        "# Importar funciones de métricas\n",
        "import sys\n",
        "sys.path.append('CodeMetrics')\n",
        "\n",
        "from BertScore import compute_bertscore_beto, compute_bertscore_sci_beto\n",
        "from SentenceBert import compute_sbert_similarity, compute_xlm_similarity, compute_scibeto_similarity\n",
        "from chrF import compute_chrf_batch\n",
        "\n",
        "print(\"✓ Métricas cargadas correctamente:\")\n",
        "print(\"  - BERTScore (BETO y SciBETO)\")\n",
        "print(\"  - Sentence-BERT (paraphrase-multilingual-mpnet-base-v2, stsb-xlm-r-multilingual, scibert-mean)\")\n",
        "print(\"  - chrF (Character n-gram F-score)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c545337c",
      "metadata": {
        "id": "c545337c"
      },
      "source": [
        "## 1. PROMPT 1: Modismo → Es Modismo (Sí/No)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f5d05af",
      "metadata": {
        "id": "6f5d05af"
      },
      "outputs": [],
      "source": [
        "GROUNTH_TRUTH = 6_533"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a5292e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55a5292e",
        "outputId": "fc2461c2-5f01-46e8-a444-9d50d7233b6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "PROMPT 1: Modismo → ¿Es Modismo? (Sí/No)\n",
            "================================================================================\n",
            "Objetivo: Evaluar si el modelo identifica correctamente que una expresión es un modismo\n",
            "Métrica: Accuracy (Exactitud)\n",
            "Justificación: Problema de clasificación binaria (Sí/No).\n",
            "   Mide el porcentaje de respuestas correctas.\n",
            "   Los errores/omisiones se cuentan como falsos negativos.\n",
            "--------------------------------------------------------------------------------\n",
            "Datos cargados: 140310 registros válidos de 140310 totales\n",
            "\n",
            "Evaluando modelo: amazon/nova-micro-v1\n",
            "  ⚠ 1 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.2464 (1610/6533 correctos)\n",
            "    - Procesados: 6532\n",
            "    - Correctos: 1610\n",
            "    - Incorrectos procesados: 4922\n",
            "    - Errores/omitidos: 1\n",
            "Evaluando modelo: microsoft/phi-4\n",
            "  ⚠ 10 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.5659 (3697/6533 correctos)\n",
            "    - Procesados: 6523\n",
            "    - Correctos: 3697\n",
            "    - Incorrectos procesados: 2826\n",
            "    - Errores/omitidos: 10\n",
            "Evaluando modelo: amazon/nova-lite-v1\n",
            "  ⚠ 3 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.3530 (2306/6533 correctos)\n",
            "    - Procesados: 6530\n",
            "    - Correctos: 2306\n",
            "    - Incorrectos procesados: 4224\n",
            "    - Errores/omitidos: 3\n",
            "Evaluando modelo: cohere/command-r-08-2024\n",
            "  ⚠ 3 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.7044 (4602/6533 correctos)\n",
            "    - Procesados: 6530\n",
            "    - Correctos: 4602\n",
            "    - Incorrectos procesados: 1928\n",
            "    - Errores/omitidos: 3\n",
            "Evaluando modelo: qwen/qwen-2.5-72b-instruct\n",
            "  ⚠ 708 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.4139 (2704/6533 correctos)\n",
            "    - Procesados: 5825\n",
            "    - Correctos: 2704\n",
            "    - Incorrectos procesados: 3121\n",
            "    - Errores/omitidos: 708\n",
            "Evaluando modelo: google/gemma-2-27b-it\n",
            "  ⚠ 15 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.8456 (5524/6533 correctos)\n",
            "    - Procesados: 6518\n",
            "    - Correctos: 5524\n",
            "    - Incorrectos procesados: 994\n",
            "    - Errores/omitidos: 15\n",
            "Evaluando modelo: meta-llama/llama-3.3-70b-instruct\n",
            "  ⚠ 390 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.7352 (4803/6533 correctos)\n",
            "    - Procesados: 6143\n",
            "    - Correctos: 4803\n",
            "    - Incorrectos procesados: 1340\n",
            "    - Errores/omitidos: 390\n",
            "Evaluando modelo: microsoft/wizardlm-2-8x22b\n",
            "  ⚠ 184 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.4491 (2934/6533 correctos)\n",
            "    - Procesados: 6349\n",
            "    - Correctos: 2934\n",
            "    - Incorrectos procesados: 3415\n",
            "    - Errores/omitidos: 184\n",
            "Evaluando modelo: meta-llama/llama-4-maverick\n",
            "  ⚠ 8 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.6781 (4430/6533 correctos)\n",
            "    - Procesados: 6525\n",
            "    - Correctos: 4430\n",
            "    - Incorrectos procesados: 2095\n",
            "    - Errores/omitidos: 8\n",
            "Evaluando modelo: qwen/qwen2.5-vl-32b-instruct:free\n",
            "  ⚠ No hay datos para qwen/qwen2.5-vl-32b-instruct:free - todos los registros cuentan como errores\n",
            "  • Accuracy: 0.0000 (0/6533 correctos)\n",
            "Evaluando modelo: x-ai/grok-3-mini-beta\n",
            "  ⚠ 284 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.1425 (931/6533 correctos)\n",
            "    - Procesados: 6249\n",
            "    - Correctos: 931\n",
            "    - Incorrectos procesados: 5318\n",
            "    - Errores/omitidos: 284\n",
            "Evaluando modelo: perplexity/sonar\n",
            "  ⚠ 279 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.4538 (2965/6533 correctos)\n",
            "    - Procesados: 6254\n",
            "    - Correctos: 2965\n",
            "    - Incorrectos procesados: 3289\n",
            "    - Errores/omitidos: 279\n",
            "Evaluando modelo: mistralai/mistral-medium-3\n",
            "  ⚠ 279 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.5644 (3687/6533 correctos)\n",
            "    - Procesados: 6254\n",
            "    - Correctos: 3687\n",
            "    - Incorrectos procesados: 2567\n",
            "    - Errores/omitidos: 279\n",
            "Evaluando modelo: mistralai/mixtral-8x7b-instruct\n",
            "  ⚠ 610 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.3369 (2201/6533 correctos)\n",
            "    - Procesados: 5923\n",
            "    - Correctos: 2201\n",
            "    - Incorrectos procesados: 3722\n",
            "    - Errores/omitidos: 610\n",
            "Evaluando modelo: google/gemini-2.5-flash\n",
            "  ⚠ 283 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.2905 (1898/6533 correctos)\n",
            "    - Procesados: 6250\n",
            "    - Correctos: 1898\n",
            "    - Incorrectos procesados: 4352\n",
            "    - Errores/omitidos: 283\n",
            "Evaluando modelo: meta-llama/llama-3.1-405b-instruct\n",
            "  ⚠ 300 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.7418 (4846/6533 correctos)\n",
            "    - Procesados: 6233\n",
            "    - Correctos: 4846\n",
            "    - Incorrectos procesados: 1387\n",
            "    - Errores/omitidos: 300\n",
            "Evaluando modelo: deepseek/deepseek-chat-v3.1\n",
            "  ⚠ 23 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.5414 (3537/6533 correctos)\n",
            "    - Procesados: 6510\n",
            "    - Correctos: 3537\n",
            "    - Incorrectos procesados: 2973\n",
            "    - Errores/omitidos: 23\n",
            "Evaluando modelo: moonshotai/kimi-k2-0905\n",
            "  ⚠ 12 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.4652 (3039/6533 correctos)\n",
            "    - Procesados: 6521\n",
            "    - Correctos: 3039\n",
            "    - Incorrectos procesados: 3482\n",
            "    - Errores/omitidos: 12\n",
            "Evaluando modelo: openai/o4-mini-high\n",
            "  ⚠ 4 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.1361 (889/6533 correctos)\n",
            "    - Procesados: 6529\n",
            "    - Correctos: 889\n",
            "    - Incorrectos procesados: 5640\n",
            "    - Errores/omitidos: 4\n",
            "Evaluando modelo: openai/gpt-4.1\n",
            "  ⚠ 18 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.4160 (2718/6533 correctos)\n",
            "    - Procesados: 6515\n",
            "    - Correctos: 2718\n",
            "    - Incorrectos procesados: 3797\n",
            "    - Errores/omitidos: 18\n",
            "Evaluando modelo: openai/o1-mini\n",
            "  • Accuracy: 0.1339 (875/6533 correctos)\n",
            "    - Procesados: 6533\n",
            "    - Correctos: 875\n",
            "    - Incorrectos procesados: 5658\n",
            "    - Errores/omitidos: 0\n",
            "Evaluando modelo: anthropic/claude-sonnet-4\n",
            "  ⚠ 2 registros omitidos se cuentan como incorrectos\n",
            "  • Accuracy: 0.4160 (2718/6533 correctos)\n",
            "    - Procesados: 6531\n",
            "    - Correctos: 2718\n",
            "    - Incorrectos procesados: 3813\n",
            "    - Errores/omitidos: 2\n",
            "Evaluando modelo: gpt-5.1\n",
            "  • Accuracy: 0.3871 (2529/6533 correctos)\n",
            "    - Procesados: 6533\n",
            "    - Correctos: 2529\n",
            "    - Incorrectos procesados: 4004\n",
            "    - Errores/omitidos: 0\n",
            "\n",
            "RESULTADOS:\n",
            "   amazon/nova-micro-v1:\n",
            "      • Accuracy:  0.2464 (1610/6533 correctos)\n",
            "   microsoft/phi-4:\n",
            "      • Accuracy:  0.5659 (3697/6533 correctos)\n",
            "   amazon/nova-lite-v1:\n",
            "      • Accuracy:  0.3530 (2306/6533 correctos)\n",
            "   cohere/command-r-08-2024:\n",
            "      • Accuracy:  0.7044 (4602/6533 correctos)\n",
            "   qwen/qwen-2.5-72b-instruct:\n",
            "      • Accuracy:  0.4139 (2704/6533 correctos)\n",
            "   google/gemma-2-27b-it:\n",
            "      • Accuracy:  0.8456 (5524/6533 correctos)\n",
            "   meta-llama/llama-3.3-70b-instruct:\n",
            "      • Accuracy:  0.7352 (4803/6533 correctos)\n",
            "   microsoft/wizardlm-2-8x22b:\n",
            "      • Accuracy:  0.4491 (2934/6533 correctos)\n",
            "   meta-llama/llama-4-maverick:\n",
            "      • Accuracy:  0.6781 (4430/6533 correctos)\n",
            "   qwen/qwen2.5-vl-32b-instruct:free:\n",
            "      • Accuracy:  0.0000 (0/6533 correctos)\n",
            "   x-ai/grok-3-mini-beta:\n",
            "      • Accuracy:  0.1425 (931/6533 correctos)\n",
            "   perplexity/sonar:\n",
            "      • Accuracy:  0.4538 (2965/6533 correctos)\n",
            "   mistralai/mistral-medium-3:\n",
            "      • Accuracy:  0.5644 (3687/6533 correctos)\n",
            "   mistralai/mixtral-8x7b-instruct:\n",
            "      • Accuracy:  0.3369 (2201/6533 correctos)\n",
            "   google/gemini-2.5-flash:\n",
            "      • Accuracy:  0.2905 (1898/6533 correctos)\n",
            "   meta-llama/llama-3.1-405b-instruct:\n",
            "      • Accuracy:  0.7418 (4846/6533 correctos)\n",
            "   deepseek/deepseek-chat-v3.1:\n",
            "      • Accuracy:  0.5414 (3537/6533 correctos)\n",
            "   moonshotai/kimi-k2-0905:\n",
            "      • Accuracy:  0.4652 (3039/6533 correctos)\n",
            "   openai/o4-mini-high:\n",
            "      • Accuracy:  0.1361 (889/6533 correctos)\n",
            "   openai/gpt-4.1:\n",
            "      • Accuracy:  0.4160 (2718/6533 correctos)\n",
            "   openai/o1-mini:\n",
            "      • Accuracy:  0.1339 (875/6533 correctos)\n",
            "   anthropic/claude-sonnet-4:\n",
            "      • Accuracy:  0.4160 (2718/6533 correctos)\n",
            "   gpt-5.1:\n",
            "      • Accuracy:  0.3871 (2529/6533 correctos)\n",
            "\n",
            "✓ Guardado en: /content/drive/MyDrive/LLMs_Metrics/Metrics_Results/prompt_1_accuracy_resultados.json\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"PROMPT 1: Modismo → ¿Es Modismo? (Sí/No)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"Objetivo: Evaluar si el modelo identifica correctamente que una expresión es un modismo\")\n",
        "print(\"Métrica: Accuracy (Exactitud)\")\n",
        "print(\"Justificación: Problema de clasificación binaria (Sí/No).\")\n",
        "print(\"   Mide el porcentaje de respuestas correctas.\")\n",
        "print(\"   Los errores/omisiones se cuentan como falsos negativos.\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Cargar datos desde JSON\n",
        "with open(os.path.join(DATA_DIR, 'prompt_1_metrics_data.json'), 'r', encoding='utf-8') as f:\n",
        "    data_p1 = json.load(f)\n",
        "\n",
        "# Filtrar datos vacíos\n",
        "data_p1_valid = [d for d in data_p1 if d.get('es_modismo_real') and d.get('es_modismo_generado')]\n",
        "print(f\"Datos cargados: {len(data_p1_valid)} registros válidos de {len(data_p1)} totales\")\n",
        "print()\n",
        "\n",
        "def normalizar_respuesta(respuesta):\n",
        "    \"\"\"Normaliza respuestas a 'Sí' o 'No'\"\"\"\n",
        "    if not respuesta:\n",
        "        return None\n",
        "    respuesta = str(respuesta).strip().lower()\n",
        "    if respuesta in ['sí', 'si', 'yes', 's', 'true', '1']:\n",
        "        return 'Sí'\n",
        "    elif respuesta in ['no', 'n', 'false', '0']:\n",
        "        return 'No'\n",
        "    return respuesta\n",
        "\n",
        "resultados_p1 = []\n",
        "\n",
        "for model in MODEL_NAMES:\n",
        "    print(f\"Evaluando modelo: {model}\")\n",
        "\n",
        "    # Filtrar datos de este modelo\n",
        "    model_data = [d for d in data_p1_valid if d.get('modelo') == model]\n",
        "\n",
        "    if not model_data:\n",
        "        print(f\"  ⚠ No hay datos para {model} - todos los registros cuentan como errores\")\n",
        "        # Agregar todos los registros como falsos negativos\n",
        "        for _ in range(GROUNTH_TRUTH):\n",
        "            resultados_p1.append({\n",
        "                'modismo': 'N/A',\n",
        "                'modelo': model,\n",
        "                'respuesta_real': 'Sí',\n",
        "                'respuesta_generada': 'No',\n",
        "                'correcto': False\n",
        "            })\n",
        "        print(f\"  • Accuracy: 0.0000 (0/{GROUNTH_TRUTH} correctos)\")\n",
        "        continue\n",
        "\n",
        "    # Calcular accuracy sobre los datos procesados\n",
        "    correctos = 0\n",
        "    for d in model_data:\n",
        "        real = normalizar_respuesta(d['es_modismo_real'])\n",
        "        generado = normalizar_respuesta(d['es_modismo_generado'])\n",
        "        correcto = (real == generado)\n",
        "\n",
        "        if correcto:\n",
        "            correctos += 1\n",
        "\n",
        "        resultados_p1.append({\n",
        "            'modismo': d['modismo'],\n",
        "            'modelo': model,\n",
        "            'respuesta_real': real,\n",
        "            'respuesta_generada': generado,\n",
        "            'correcto': correcto\n",
        "        })\n",
        "\n",
        "    # Calcular registros faltantes (omitidos por errores)\n",
        "    registros_procesados = len(model_data)\n",
        "    registros_faltantes = GROUNTH_TRUTH - registros_procesados\n",
        "\n",
        "    # Agregar registros faltantes como falsos negativos\n",
        "    if registros_faltantes > 0:\n",
        "        print(f\"  ⚠ {registros_faltantes} registros omitidos se cuentan como incorrectos\")\n",
        "        for _ in range(registros_faltantes):\n",
        "            resultados_p1.append({\n",
        "                'modismo': 'ERROR/OMITIDO',\n",
        "                'modelo': model,\n",
        "                'respuesta_real': 'Sí',\n",
        "                'respuesta_generada': 'No',\n",
        "                'correcto': False\n",
        "            })\n",
        "\n",
        "    # Calcular accuracy sobre el total (GROUNTH_TRUTH)\n",
        "    accuracy = correctos / GROUNTH_TRUTH\n",
        "    print(f\"  • Accuracy: {accuracy:.4f} ({correctos}/{GROUNTH_TRUTH} correctos)\")\n",
        "    print(f\"    - Procesados: {registros_procesados}\")\n",
        "    print(f\"    - Correctos: {correctos}\")\n",
        "    print(f\"    - Incorrectos procesados: {registros_procesados - correctos}\")\n",
        "    print(f\"    - Errores/omitidos: {registros_faltantes}\")\n",
        "\n",
        "# Guardar resultados\n",
        "output_file = os.path.join(OUTPUT_DIR, 'prompt_1_accuracy_resultados.json')\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(resultados_p1, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print()\n",
        "print(\"RESULTADOS:\")\n",
        "for model in MODEL_NAMES:\n",
        "    model_results = [r for r in resultados_p1 if r['modelo'] == model]\n",
        "    if model_results:\n",
        "        correctos = sum(1 for r in model_results if r['correcto'])\n",
        "        total = len(model_results)\n",
        "        accuracy = correctos / GROUNTH_TRUTH  # Siempre sobre el ground truth\n",
        "        print(f\"   {model}:\")\n",
        "        print(f\"      • Accuracy:  {accuracy:.4f} ({correctos}/{GROUNTH_TRUTH} correctos)\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(f\"✓ Guardado en: {output_file}\")\n",
        "print(\"=\"*80)\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38dc0361",
      "metadata": {
        "id": "38dc0361"
      },
      "source": [
        "## 2. PROMPT 2: Modismo → Definición"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd4e861b",
      "metadata": {
        "id": "bd4e861b"
      },
      "outputs": [],
      "source": [
        "GROUNTH_TRUTH = 6_533"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3620403",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3620403",
        "outputId": "aaafb355-e268-49a5-f11e-781f9045f93d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "PROMPT 2: Modismo → Definición\n",
            "================================================================================\n",
            "Objetivo: Evaluar si el modelo puede generar una definición correcta del modismo\n",
            "Métricas:\n",
            "  - BERTScore (BETO y SciBETO): Similitud semántica con embeddings de BERT\n",
            "  - Sentence-BERT: Similitud con modelo multilingüe paraphrase-mpnet\n",
            "  - chrF: Character n-gram F-score\n",
            "Nota: Los errores/omisiones se cuentan con score 0 en todas las métricas.\n",
            "--------------------------------------------------------------------------------\n",
            "Datos cargados: 136369 registros válidos de 136369 totales\n",
            "\n",
            "\n",
            "============================================================\n",
            "Calculando BERTScore con BETO\n",
            "============================================================\n",
            "Evaluando modelo: amazon/nova-micro-v1\n",
            "  ⚠ 12 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4368\n",
            "  • Recall:    0.4468\n",
            "  • F1 Score:  0.4408\n",
            "    - Procesados: 6521\n",
            "    - Errores/omitidos: 12\n",
            "Evaluando modelo: microsoft/phi-4\n",
            "  ⚠ 381 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.3993\n",
            "  • Recall:    0.4168\n",
            "  • F1 Score:  0.4069\n",
            "    - Procesados: 6152\n",
            "    - Errores/omitidos: 381\n",
            "Evaluando modelo: amazon/nova-lite-v1\n",
            "  ⚠ 75 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4382\n",
            "  • Recall:    0.4301\n",
            "  • F1 Score:  0.4331\n",
            "    - Procesados: 6458\n",
            "    - Errores/omitidos: 75\n",
            "Evaluando modelo: cohere/command-r-08-2024\n",
            "  ⚠ 357 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4227\n",
            "  • Recall:    0.4375\n",
            "  • F1 Score:  0.4290\n",
            "    - Procesados: 6176\n",
            "    - Errores/omitidos: 357\n",
            "Evaluando modelo: qwen/qwen-2.5-72b-instruct\n",
            "  ⚠ 733 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4058\n",
            "  • Recall:    0.4096\n",
            "  • F1 Score:  0.4068\n",
            "    - Procesados: 5800\n",
            "    - Errores/omitidos: 733\n",
            "Evaluando modelo: google/gemma-2-27b-it\n",
            "  ⚠ 153 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4367\n",
            "  • Recall:    0.4353\n",
            "  • F1 Score:  0.4350\n",
            "    - Procesados: 6380\n",
            "    - Errores/omitidos: 153\n",
            "Evaluando modelo: meta-llama/llama-3.3-70b-instruct\n",
            "  ⚠ 378 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4290\n",
            "  • Recall:    0.4178\n",
            "  • F1 Score:  0.4223\n",
            "    - Procesados: 6155\n",
            "    - Errores/omitidos: 378\n",
            "Evaluando modelo: microsoft/wizardlm-2-8x22b\n",
            "  ⚠ 150 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4336\n",
            "  • Recall:    0.4612\n",
            "  • F1 Score:  0.4459\n",
            "    - Procesados: 6383\n",
            "    - Errores/omitidos: 150\n",
            "Evaluando modelo: meta-llama/llama-4-maverick\n",
            "  ⚠ 30 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4538\n",
            "  • Recall:    0.4651\n",
            "  • F1 Score:  0.4583\n",
            "    - Procesados: 6503\n",
            "    - Errores/omitidos: 30\n",
            "Evaluando modelo: qwen/qwen2.5-vl-32b-instruct:free\n",
            "  ⚠ No hay datos para qwen/qwen2.5-vl-32b-instruct:free - todos los registros con score 0\n",
            "  • F1 Score: 0.0000 (0/6533)\n",
            "  ⚠ 6533 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.0000\n",
            "  • Recall:    0.0000\n",
            "  • F1 Score:  0.0000\n",
            "    - Procesados: 0\n",
            "    - Errores/omitidos: 6533\n",
            "Evaluando modelo: x-ai/grok-3-mini-beta\n",
            "  ⚠ 280 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4357\n",
            "  • Recall:    0.4439\n",
            "  • F1 Score:  0.4388\n",
            "    - Procesados: 6253\n",
            "    - Errores/omitidos: 280\n",
            "Evaluando modelo: perplexity/sonar\n",
            "  ⚠ 354 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4941\n",
            "  • Recall:    0.5166\n",
            "  • F1 Score:  0.5037\n",
            "    - Procesados: 6179\n",
            "    - Errores/omitidos: 354\n",
            "Evaluando modelo: mistralai/mistral-medium-3\n",
            "  ⚠ 287 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4276\n",
            "  • Recall:    0.4424\n",
            "  • F1 Score:  0.4339\n",
            "    - Procesados: 6246\n",
            "    - Errores/omitidos: 287\n",
            "Evaluando modelo: mistralai/mixtral-8x7b-instruct\n",
            "  ⚠ 299 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4366\n",
            "  • Recall:    0.4495\n",
            "  • F1 Score:  0.4420\n",
            "    - Procesados: 6234\n",
            "    - Errores/omitidos: 299\n",
            "Evaluando modelo: google/gemini-2.5-flash\n",
            "  ⚠ 287 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4554\n",
            "  • Recall:    0.4782\n",
            "  • F1 Score:  0.4655\n",
            "    - Procesados: 6246\n",
            "    - Errores/omitidos: 287\n",
            "Evaluando modelo: meta-llama/llama-3.1-405b-instruct\n",
            "  ⚠ 702 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.3985\n",
            "  • Recall:    0.4100\n",
            "  • F1 Score:  0.4032\n",
            "    - Procesados: 5831\n",
            "    - Errores/omitidos: 702\n",
            "Evaluando modelo: deepseek/deepseek-chat-v3.1\n",
            "  ⚠ 24 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4492\n",
            "  • Recall:    0.4754\n",
            "  • F1 Score:  0.4608\n",
            "    - Procesados: 6509\n",
            "    - Errores/omitidos: 24\n",
            "Evaluando modelo: moonshotai/kimi-k2-0905\n",
            "  ⚠ 2839 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.2553\n",
            "  • Recall:    0.2655\n",
            "  • F1 Score:  0.2596\n",
            "    - Procesados: 3694\n",
            "    - Errores/omitidos: 2839\n",
            "Evaluando modelo: openai/o4-mini-high\n",
            "  ⚠ 3 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4455\n",
            "  • Recall:    0.4641\n",
            "  • F1 Score:  0.4536\n",
            "    - Procesados: 6530\n",
            "    - Errores/omitidos: 3\n",
            "Evaluando modelo: openai/gpt-4.1\n",
            "  ⚠ 10 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4637\n",
            "  • Recall:    0.4901\n",
            "  • F1 Score:  0.4755\n",
            "    - Procesados: 6523\n",
            "    - Errores/omitidos: 10\n",
            "Evaluando modelo: openai/o1-mini\n",
            "  ⚠ 1 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4483\n",
            "  • Recall:    0.4660\n",
            "  • F1 Score:  0.4560\n",
            "    - Procesados: 6532\n",
            "    - Errores/omitidos: 1\n",
            "Evaluando modelo: anthropic/claude-sonnet-4\n",
            "  • Precision: 0.4733\n",
            "  • Recall:    0.4936\n",
            "  • F1 Score:  0.4821\n",
            "    - Procesados: 6533\n",
            "    - Errores/omitidos: 0\n",
            "Evaluando modelo: gpt-5.1\n",
            "  ⚠ 2 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4586\n",
            "  • Recall:    0.4992\n",
            "  • F1 Score:  0.4770\n",
            "    - Procesados: 6531\n",
            "    - Errores/omitidos: 2\n",
            "\n",
            "RESULTADOS con BETO:\n",
            "   amazon/nova-micro-v1:\n",
            "      • Precision: 0.4368\n",
            "      • Recall:    0.4468\n",
            "      • F1 Score:  0.4408 (±0.0916) [6533/6533]\n",
            "   microsoft/phi-4:\n",
            "      • Precision: 0.3993\n",
            "      • Recall:    0.4168\n",
            "      • F1 Score:  0.4069 (±0.1280) [6533/6533]\n",
            "   amazon/nova-lite-v1:\n",
            "      • Precision: 0.4382\n",
            "      • Recall:    0.4301\n",
            "      • F1 Score:  0.4331 (±0.1042) [6533/6533]\n",
            "   cohere/command-r-08-2024:\n",
            "      • Precision: 0.4227\n",
            "      • Recall:    0.4375\n",
            "      • F1 Score:  0.4290 (±0.1373) [6533/6533]\n",
            "   qwen/qwen-2.5-72b-instruct:\n",
            "      • Precision: 0.4058\n",
            "      • Recall:    0.4096\n",
            "      • F1 Score:  0.4068 (±0.1740) [6533/6533]\n",
            "   google/gemma-2-27b-it:\n",
            "      • Precision: 0.4367\n",
            "      • Recall:    0.4353\n",
            "      • F1 Score:  0.4350 (±0.1132) [6533/6533]\n",
            "   meta-llama/llama-3.3-70b-instruct:\n",
            "      • Precision: 0.4290\n",
            "      • Recall:    0.4178\n",
            "      • F1 Score:  0.4223 (±0.1447) [6533/6533]\n",
            "   microsoft/wizardlm-2-8x22b:\n",
            "      • Precision: 0.4336\n",
            "      • Recall:    0.4612\n",
            "      • F1 Score:  0.4459 (±0.1122) [6533/6533]\n",
            "   meta-llama/llama-4-maverick:\n",
            "      • Precision: 0.4538\n",
            "      • Recall:    0.4651\n",
            "      • F1 Score:  0.4583 (±0.1091) [6533/6533]\n",
            "   qwen/qwen2.5-vl-32b-instruct:free:\n",
            "      • Precision: 0.0000\n",
            "      • Recall:    0.0000\n",
            "      • F1 Score:  0.0000 (±0.0000) [13066/6533]\n",
            "   x-ai/grok-3-mini-beta:\n",
            "      • Precision: 0.4357\n",
            "      • Recall:    0.4439\n",
            "      • F1 Score:  0.4388 (±0.1350) [6533/6533]\n",
            "   perplexity/sonar:\n",
            "      • Precision: 0.4941\n",
            "      • Recall:    0.5166\n",
            "      • F1 Score:  0.5037 (±0.1773) [6533/6533]\n",
            "   mistralai/mistral-medium-3:\n",
            "      • Precision: 0.4276\n",
            "      • Recall:    0.4424\n",
            "      • F1 Score:  0.4339 (±0.1330) [6533/6533]\n",
            "   mistralai/mixtral-8x7b-instruct:\n",
            "      • Precision: 0.4366\n",
            "      • Recall:    0.4495\n",
            "      • F1 Score:  0.4420 (±0.1360) [6533/6533]\n",
            "   google/gemini-2.5-flash:\n",
            "      • Precision: 0.4554\n",
            "      • Recall:    0.4782\n",
            "      • F1 Score:  0.4655 (±0.1446) [6533/6533]\n",
            "   meta-llama/llama-3.1-405b-instruct:\n",
            "      • Precision: 0.3985\n",
            "      • Recall:    0.4100\n",
            "      • F1 Score:  0.4032 (±0.1668) [6533/6533]\n",
            "   deepseek/deepseek-chat-v3.1:\n",
            "      • Precision: 0.4492\n",
            "      • Recall:    0.4754\n",
            "      • F1 Score:  0.4608 (±0.0995) [6533/6533]\n",
            "   moonshotai/kimi-k2-0905:\n",
            "      • Precision: 0.2553\n",
            "      • Recall:    0.2655\n",
            "      • F1 Score:  0.2596 (±0.2393) [6533/6533]\n",
            "   openai/o4-mini-high:\n",
            "      • Precision: 0.4455\n",
            "      • Recall:    0.4641\n",
            "      • F1 Score:  0.4536 (±0.1019) [6533/6533]\n",
            "   openai/gpt-4.1:\n",
            "      • Precision: 0.4637\n",
            "      • Recall:    0.4901\n",
            "      • F1 Score:  0.4755 (±0.1063) [6533/6533]\n",
            "   openai/o1-mini:\n",
            "      • Precision: 0.4483\n",
            "      • Recall:    0.4660\n",
            "      • F1 Score:  0.4560 (±0.1015) [6533/6533]\n",
            "   anthropic/claude-sonnet-4:\n",
            "      • Precision: 0.4733\n",
            "      • Recall:    0.4936\n",
            "      • F1 Score:  0.4821 (±0.1109) [6533/6533]\n",
            "   gpt-5.1:\n",
            "      • Precision: 0.4586\n",
            "      • Recall:    0.4992\n",
            "      • F1 Score:  0.4770 (±0.1005) [6533/6533]\n",
            "\n",
            "✓ Guardado en: /content/drive/MyDrive/LLMs_Metrics/Metrics_Results/prompt_2_beto_bertscore_resultados.json\n",
            "\n",
            "============================================================\n",
            "Calculando BERTScore con SciBETO\n",
            "============================================================\n",
            "Evaluando modelo: amazon/nova-micro-v1\n",
            "  ⚠ 12 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7322\n",
            "  • Recall:    0.7343\n",
            "  • F1 Score:  0.7329\n",
            "    - Procesados: 6521\n",
            "    - Errores/omitidos: 12\n",
            "Evaluando modelo: microsoft/phi-4\n",
            "  ⚠ 381 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.6836\n",
            "  • Recall:    0.6917\n",
            "  • F1 Score:  0.6873\n",
            "    - Procesados: 6152\n",
            "    - Errores/omitidos: 381\n",
            "Evaluando modelo: amazon/nova-lite-v1\n",
            "  ⚠ 75 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7399\n",
            "  • Recall:    0.7276\n",
            "  • F1 Score:  0.7333\n",
            "    - Procesados: 6458\n",
            "    - Errores/omitidos: 75\n",
            "Evaluando modelo: cohere/command-r-08-2024\n",
            "  ⚠ 357 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.6948\n",
            "  • Recall:    0.7007\n",
            "  • F1 Score:  0.6974\n",
            "    - Procesados: 6176\n",
            "    - Errores/omitidos: 357\n",
            "Evaluando modelo: qwen/qwen-2.5-72b-instruct\n",
            "  ⚠ 733 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.6633\n",
            "  • Recall:    0.6610\n",
            "  • F1 Score:  0.6618\n",
            "    - Procesados: 5800\n",
            "    - Errores/omitidos: 733\n",
            "Evaluando modelo: google/gemma-2-27b-it\n",
            "  ⚠ 153 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7282\n",
            "  • Recall:    0.7204\n",
            "  • F1 Score:  0.7239\n",
            "    - Procesados: 6380\n",
            "    - Errores/omitidos: 153\n",
            "Evaluando modelo: meta-llama/llama-3.3-70b-instruct\n",
            "  ⚠ 378 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7090\n",
            "  • Recall:    0.6958\n",
            "  • F1 Score:  0.7020\n",
            "    - Procesados: 6155\n",
            "    - Errores/omitidos: 378\n",
            "Evaluando modelo: microsoft/wizardlm-2-8x22b\n",
            "  ⚠ 150 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7107\n",
            "  • Recall:    0.7235\n",
            "  • F1 Score:  0.7167\n",
            "    - Procesados: 6383\n",
            "    - Errores/omitidos: 150\n",
            "Evaluando modelo: meta-llama/llama-4-maverick\n",
            "  ⚠ 30 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7348\n",
            "  • Recall:    0.7404\n",
            "  • F1 Score:  0.7372\n",
            "    - Procesados: 6503\n",
            "    - Errores/omitidos: 30\n",
            "Evaluando modelo: qwen/qwen2.5-vl-32b-instruct:free\n",
            "  ⚠ No hay datos para qwen/qwen2.5-vl-32b-instruct:free - todos los registros con score 0\n",
            "  • F1 Score: 0.0000 (0/6533)\n",
            "  ⚠ 6533 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.0000\n",
            "  • Recall:    0.0000\n",
            "  • F1 Score:  0.0000\n",
            "    - Procesados: 0\n",
            "    - Errores/omitidos: 6533\n",
            "Evaluando modelo: x-ai/grok-3-mini-beta\n",
            "  ⚠ 280 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7160\n",
            "  • Recall:    0.7128\n",
            "  • F1 Score:  0.7140\n",
            "    - Procesados: 6253\n",
            "    - Errores/omitidos: 280\n",
            "Evaluando modelo: perplexity/sonar\n",
            "  ⚠ 354 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7168\n",
            "  • Recall:    0.7308\n",
            "  • F1 Score:  0.7232\n",
            "    - Procesados: 6179\n",
            "    - Errores/omitidos: 354\n",
            "Evaluando modelo: mistralai/mistral-medium-3\n",
            "  ⚠ 287 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7059\n",
            "  • Recall:    0.7114\n",
            "  • F1 Score:  0.7083\n",
            "    - Procesados: 6246\n",
            "    - Errores/omitidos: 287\n",
            "Evaluando modelo: mistralai/mixtral-8x7b-instruct\n",
            "  ⚠ 299 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7070\n",
            "  • Recall:    0.7106\n",
            "  • F1 Score:  0.7084\n",
            "    - Procesados: 6234\n",
            "    - Errores/omitidos: 299\n",
            "Evaluando modelo: google/gemini-2.5-flash\n",
            "  ⚠ 287 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7075\n",
            "  • Recall:    0.7204\n",
            "  • F1 Score:  0.7135\n",
            "    - Procesados: 6246\n",
            "    - Errores/omitidos: 287\n",
            "Evaluando modelo: meta-llama/llama-3.1-405b-instruct\n",
            "  ⚠ 702 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.6557\n",
            "  • Recall:    0.6611\n",
            "  • F1 Score:  0.6580\n",
            "    - Procesados: 5831\n",
            "    - Errores/omitidos: 702\n",
            "Evaluando modelo: deepseek/deepseek-chat-v3.1\n",
            "  ⚠ 24 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7254\n",
            "  • Recall:    0.7415\n",
            "  • F1 Score:  0.7329\n",
            "    - Procesados: 6509\n",
            "    - Errores/omitidos: 24\n",
            "Evaluando modelo: moonshotai/kimi-k2-0905\n",
            "  ⚠ 2839 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4145\n",
            "  • Recall:    0.4211\n",
            "  • F1 Score:  0.4175\n",
            "    - Procesados: 3694\n",
            "    - Errores/omitidos: 2839\n",
            "Evaluando modelo: openai/o4-mini-high\n",
            "  ⚠ 3 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7362\n",
            "  • Recall:    0.7448\n",
            "  • F1 Score:  0.7401\n",
            "    - Procesados: 6530\n",
            "    - Errores/omitidos: 3\n",
            "Evaluando modelo: openai/gpt-4.1\n",
            "  ⚠ 10 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7351\n",
            "  • Recall:    0.7506\n",
            "  • F1 Score:  0.7424\n",
            "    - Procesados: 6523\n",
            "    - Errores/omitidos: 10\n",
            "Evaluando modelo: openai/o1-mini\n",
            "  ⚠ 1 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7371\n",
            "  • Recall:    0.7454\n",
            "  • F1 Score:  0.7408\n",
            "    - Procesados: 6532\n",
            "    - Errores/omitidos: 1\n",
            "Evaluando modelo: anthropic/claude-sonnet-4\n",
            "  • Precision: 0.7395\n",
            "  • Recall:    0.7538\n",
            "  • F1 Score:  0.7461\n",
            "    - Procesados: 6533\n",
            "    - Errores/omitidos: 0\n",
            "Evaluando modelo: gpt-5.1\n",
            "  ⚠ 2 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7205\n",
            "  • Recall:    0.7504\n",
            "  • F1 Score:  0.7348\n",
            "    - Procesados: 6531\n",
            "    - Errores/omitidos: 2\n",
            "\n",
            "RESULTADOS con SciBETO:\n",
            "   amazon/nova-micro-v1:\n",
            "      • Precision: 0.7322\n",
            "      • Recall:    0.7343\n",
            "      • F1 Score:  0.7329 (±0.0469) [6533/6533]\n",
            "   microsoft/phi-4:\n",
            "      • Precision: 0.6836\n",
            "      • Recall:    0.6917\n",
            "      • F1 Score:  0.6873 (±0.1738) [6533/6533]\n",
            "   amazon/nova-lite-v1:\n",
            "      • Precision: 0.7399\n",
            "      • Recall:    0.7276\n",
            "      • F1 Score:  0.7333 (±0.0870) [6533/6533]\n",
            "   cohere/command-r-08-2024:\n",
            "      • Precision: 0.6948\n",
            "      • Recall:    0.7007\n",
            "      • F1 Score:  0.6974 (±0.1711) [6533/6533]\n",
            "   qwen/qwen-2.5-72b-instruct:\n",
            "      • Precision: 0.6633\n",
            "      • Recall:    0.6610\n",
            "      • F1 Score:  0.6618 (±0.2382) [6533/6533]\n",
            "   google/gemma-2-27b-it:\n",
            "      • Precision: 0.7282\n",
            "      • Recall:    0.7204\n",
            "      • F1 Score:  0.7239 (±0.1176) [6533/6533]\n",
            "   meta-llama/llama-3.3-70b-instruct:\n",
            "      • Precision: 0.7090\n",
            "      • Recall:    0.6958\n",
            "      • F1 Score:  0.7020 (±0.1782) [6533/6533]\n",
            "   microsoft/wizardlm-2-8x22b:\n",
            "      • Precision: 0.7107\n",
            "      • Recall:    0.7235\n",
            "      • F1 Score:  0.7167 (±0.1152) [6533/6533]\n",
            "   meta-llama/llama-4-maverick:\n",
            "      • Precision: 0.7348\n",
            "      • Recall:    0.7404\n",
            "      • F1 Score:  0.7372 (±0.0644) [6533/6533]\n",
            "   qwen/qwen2.5-vl-32b-instruct:free:\n",
            "      • Precision: 0.0000\n",
            "      • Recall:    0.0000\n",
            "      • F1 Score:  0.0000 (±0.0000) [13066/6533]\n",
            "   x-ai/grok-3-mini-beta:\n",
            "      • Precision: 0.7160\n",
            "      • Recall:    0.7128\n",
            "      • F1 Score:  0.7140 (±0.1554) [6533/6533]\n",
            "   perplexity/sonar:\n",
            "      • Precision: 0.7168\n",
            "      • Recall:    0.7308\n",
            "      • F1 Score:  0.7232 (±0.1808) [6533/6533]\n",
            "   mistralai/mistral-medium-3:\n",
            "      • Precision: 0.7059\n",
            "      • Recall:    0.7114\n",
            "      • F1 Score:  0.7083 (±0.1560) [6533/6533]\n",
            "   mistralai/mixtral-8x7b-instruct:\n",
            "      • Precision: 0.7070\n",
            "      • Recall:    0.7106\n",
            "      • F1 Score:  0.7084 (±0.1597) [6533/6533]\n",
            "   google/gemini-2.5-flash:\n",
            "      • Precision: 0.7075\n",
            "      • Recall:    0.7204\n",
            "      • F1 Score:  0.7135 (±0.1580) [6533/6533]\n",
            "   meta-llama/llama-3.1-405b-instruct:\n",
            "      • Precision: 0.6557\n",
            "      • Recall:    0.6611\n",
            "      • F1 Score:  0.6580 (±0.2309) [6533/6533]\n",
            "   deepseek/deepseek-chat-v3.1:\n",
            "      • Precision: 0.7254\n",
            "      • Recall:    0.7415\n",
            "      • F1 Score:  0.7329 (±0.0571) [6533/6533]\n",
            "   moonshotai/kimi-k2-0905:\n",
            "      • Precision: 0.4145\n",
            "      • Recall:    0.4211\n",
            "      • F1 Score:  0.4175 (±0.3671) [6533/6533]\n",
            "   openai/o4-mini-high:\n",
            "      • Precision: 0.7362\n",
            "      • Recall:    0.7448\n",
            "      • F1 Score:  0.7401 (±0.0409) [6533/6533]\n",
            "   openai/gpt-4.1:\n",
            "      • Precision: 0.7351\n",
            "      • Recall:    0.7506\n",
            "      • F1 Score:  0.7424 (±0.0492) [6533/6533]\n",
            "   openai/o1-mini:\n",
            "      • Precision: 0.7371\n",
            "      • Recall:    0.7454\n",
            "      • F1 Score:  0.7408 (±0.0393) [6533/6533]\n",
            "   anthropic/claude-sonnet-4:\n",
            "      • Precision: 0.7395\n",
            "      • Recall:    0.7538\n",
            "      • F1 Score:  0.7461 (±0.0418) [6533/6533]\n",
            "   gpt-5.1:\n",
            "      • Precision: 0.7205\n",
            "      • Recall:    0.7504\n",
            "      • F1 Score:  0.7348 (±0.0396) [6533/6533]\n",
            "\n",
            "✓ Guardado en: /content/drive/MyDrive/LLMs_Metrics/Metrics_Results/prompt_2_scibeto_bertscore_resultados.json\n",
            "\n",
            "============================================================\n",
            "Calculando Sentence-BERT Similarity con SciBETO-mean\n",
            "============================================================\n",
            "Evaluando modelo: amazon/nova-micro-v1\n",
            "  ⚠ 12 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6585\n",
            "    - Procesados: 6521\n",
            "    - Errores/omitidos: 12\n",
            "Evaluando modelo: microsoft/phi-4\n",
            "  ⚠ 381 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6325\n",
            "    - Procesados: 6152\n",
            "    - Errores/omitidos: 381\n",
            "Evaluando modelo: amazon/nova-lite-v1\n",
            "  ⚠ 75 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6193\n",
            "    - Procesados: 6458\n",
            "    - Errores/omitidos: 75\n",
            "Evaluando modelo: cohere/command-r-08-2024\n",
            "  ⚠ 357 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6404\n",
            "    - Procesados: 6176\n",
            "    - Errores/omitidos: 357\n",
            "Evaluando modelo: qwen/qwen-2.5-72b-instruct\n",
            "  ⚠ 733 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5856\n",
            "    - Procesados: 5800\n",
            "    - Errores/omitidos: 733\n",
            "Evaluando modelo: google/gemma-2-27b-it\n",
            "  ⚠ 153 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6319\n",
            "    - Procesados: 6380\n",
            "    - Errores/omitidos: 153\n",
            "Evaluando modelo: meta-llama/llama-3.3-70b-instruct\n",
            "  ⚠ 378 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5834\n",
            "    - Procesados: 6155\n",
            "    - Errores/omitidos: 378\n",
            "Evaluando modelo: microsoft/wizardlm-2-8x22b\n",
            "  ⚠ 150 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6752\n",
            "    - Procesados: 6383\n",
            "    - Errores/omitidos: 150\n",
            "Evaluando modelo: meta-llama/llama-4-maverick\n",
            "  ⚠ 30 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6582\n",
            "    - Procesados: 6503\n",
            "    - Errores/omitidos: 30\n",
            "Evaluando modelo: qwen/qwen2.5-vl-32b-instruct:free\n",
            "  ⚠ No hay datos para qwen/qwen2.5-vl-32b-instruct:free - todos los registros con similarity 0\n",
            "  • Similitud: 0.0000 (0/6533)\n",
            "  ⚠ 6533 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.0000\n",
            "    - Procesados: 0\n",
            "    - Errores/omitidos: 6533\n",
            "Evaluando modelo: x-ai/grok-3-mini-beta\n",
            "  ⚠ 280 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6425\n",
            "    - Procesados: 6253\n",
            "    - Errores/omitidos: 280\n",
            "Evaluando modelo: perplexity/sonar\n",
            "  ⚠ 354 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6782\n",
            "    - Procesados: 6179\n",
            "    - Errores/omitidos: 354\n",
            "Evaluando modelo: mistralai/mistral-medium-3\n",
            "  ⚠ 287 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6450\n",
            "    - Procesados: 6246\n",
            "    - Errores/omitidos: 287\n",
            "Evaluando modelo: mistralai/mixtral-8x7b-instruct\n",
            "  ⚠ 299 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6515\n",
            "    - Procesados: 6234\n",
            "    - Errores/omitidos: 299\n",
            "Evaluando modelo: google/gemini-2.5-flash\n",
            "  ⚠ 287 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6745\n",
            "    - Procesados: 6246\n",
            "    - Errores/omitidos: 287\n",
            "Evaluando modelo: meta-llama/llama-3.1-405b-instruct\n",
            "  ⚠ 702 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5902\n",
            "    - Procesados: 5831\n",
            "    - Errores/omitidos: 702\n",
            "Evaluando modelo: deepseek/deepseek-chat-v3.1\n",
            "  ⚠ 24 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6886\n",
            "    - Procesados: 6509\n",
            "    - Errores/omitidos: 24\n",
            "Evaluando modelo: moonshotai/kimi-k2-0905\n",
            "  ⚠ 2839 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3834\n",
            "    - Procesados: 3694\n",
            "    - Errores/omitidos: 2839\n",
            "Evaluando modelo: openai/o4-mini-high\n",
            "  ⚠ 3 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6768\n",
            "    - Procesados: 6530\n",
            "    - Errores/omitidos: 3\n",
            "Evaluando modelo: openai/gpt-4.1\n",
            "  ⚠ 10 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6984\n",
            "    - Procesados: 6523\n",
            "    - Errores/omitidos: 10\n",
            "Evaluando modelo: openai/o1-mini\n",
            "  ⚠ 1 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6778\n",
            "    - Procesados: 6532\n",
            "    - Errores/omitidos: 1\n",
            "Evaluando modelo: anthropic/claude-sonnet-4\n",
            "  • Similitud: 0.6937\n",
            "    - Procesados: 6533\n",
            "    - Errores/omitidos: 0\n",
            "Evaluando modelo: gpt-5.1\n",
            "  ⚠ 2 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.7094\n",
            "    - Procesados: 6531\n",
            "    - Errores/omitidos: 2\n",
            "\n",
            "RESULTADOS con Sentence-BERT (SciBETO-mean):\n",
            "   amazon/nova-micro-v1:\n",
            "      • Similitud: 0.6585 (±0.1543) [6533/6533]\n",
            "   microsoft/phi-4:\n",
            "      • Similitud: 0.6325 (±0.2154) [6533/6533]\n",
            "   amazon/nova-lite-v1:\n",
            "      • Similitud: 0.6193 (±0.1607) [6533/6533]\n",
            "   cohere/command-r-08-2024:\n",
            "      • Similitud: 0.6404 (±0.2157) [6533/6533]\n",
            "   qwen/qwen-2.5-72b-instruct:\n",
            "      • Similitud: 0.5856 (±0.2557) [6533/6533]\n",
            "   google/gemma-2-27b-it:\n",
            "      • Similitud: 0.6319 (±0.1766) [6533/6533]\n",
            "   meta-llama/llama-3.3-70b-instruct:\n",
            "      • Similitud: 0.5834 (±0.2040) [6533/6533]\n",
            "   microsoft/wizardlm-2-8x22b:\n",
            "      • Similitud: 0.6752 (±0.1848) [6533/6533]\n",
            "   meta-llama/llama-4-maverick:\n",
            "      • Similitud: 0.6582 (±0.1623) [6533/6533]\n",
            "   qwen/qwen2.5-vl-32b-instruct:free:\n",
            "      • Similitud: 0.0000 (±0.0000) [13066/6533]\n",
            "   x-ai/grok-3-mini-beta:\n",
            "      • Similitud: 0.6425 (±0.2041) [6533/6533]\n",
            "   perplexity/sonar:\n",
            "      • Similitud: 0.6782 (±0.2305) [6533/6533]\n",
            "   mistralai/mistral-medium-3:\n",
            "      • Similitud: 0.6450 (±0.2034) [6533/6533]\n",
            "   mistralai/mixtral-8x7b-instruct:\n",
            "      • Similitud: 0.6515 (±0.2075) [6533/6533]\n",
            "   google/gemini-2.5-flash:\n",
            "      • Similitud: 0.6745 (±0.2128) [6533/6533]\n",
            "   meta-llama/llama-3.1-405b-instruct:\n",
            "      • Similitud: 0.5902 (±0.2511) [6533/6533]\n",
            "   deepseek/deepseek-chat-v3.1:\n",
            "      • Similitud: 0.6886 (±0.1608) [6533/6533]\n",
            "   moonshotai/kimi-k2-0905:\n",
            "      • Similitud: 0.3834 (±0.3564) [6533/6533]\n",
            "   openai/o4-mini-high:\n",
            "      • Similitud: 0.6768 (±0.1555) [6533/6533]\n",
            "   openai/gpt-4.1:\n",
            "      • Similitud: 0.6984 (±0.1618) [6533/6533]\n",
            "   openai/o1-mini:\n",
            "      • Similitud: 0.6778 (±0.1560) [6533/6533]\n",
            "   anthropic/claude-sonnet-4:\n",
            "      • Similitud: 0.6937 (±0.1609) [6533/6533]\n",
            "   gpt-5.1:\n",
            "      • Similitud: 0.7094 (±0.1618) [6533/6533]\n",
            "\n",
            "✓ Guardado en: /content/drive/MyDrive/LLMs_Metrics/Metrics_Results/prompt_2_scibeto-mean_sbert_similarity_resultados.json\n",
            "\n",
            "============================================================\n",
            "Calculando Sentence-BERT Similarity con paraphrase-mpnet\n",
            "============================================================\n",
            "Evaluando modelo: amazon/nova-micro-v1\n",
            "  ⚠ 12 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3284\n",
            "    - Procesados: 6521\n",
            "    - Errores/omitidos: 12\n",
            "Evaluando modelo: microsoft/phi-4\n",
            "  ⚠ 381 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.2662\n",
            "    - Procesados: 6152\n",
            "    - Errores/omitidos: 381\n",
            "Evaluando modelo: amazon/nova-lite-v1\n",
            "  ⚠ 75 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3363\n",
            "    - Procesados: 6458\n",
            "    - Errores/omitidos: 75\n",
            "Evaluando modelo: cohere/command-r-08-2024\n",
            "  ⚠ 357 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3303\n",
            "    - Procesados: 6176\n",
            "    - Errores/omitidos: 357\n",
            "Evaluando modelo: qwen/qwen-2.5-72b-instruct\n",
            "  ⚠ 733 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3291\n",
            "    - Procesados: 5800\n",
            "    - Errores/omitidos: 733\n",
            "Evaluando modelo: google/gemma-2-27b-it\n",
            "  ⚠ 153 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3116\n",
            "    - Procesados: 6380\n",
            "    - Errores/omitidos: 153\n",
            "Evaluando modelo: meta-llama/llama-3.3-70b-instruct\n",
            "  ⚠ 378 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3451\n",
            "    - Procesados: 6155\n",
            "    - Errores/omitidos: 378\n",
            "Evaluando modelo: microsoft/wizardlm-2-8x22b\n",
            "  ⚠ 150 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3222\n",
            "    - Procesados: 6383\n",
            "    - Errores/omitidos: 150\n",
            "Evaluando modelo: meta-llama/llama-4-maverick\n",
            "  ⚠ 30 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3676\n",
            "    - Procesados: 6503\n",
            "    - Errores/omitidos: 30\n",
            "Evaluando modelo: qwen/qwen2.5-vl-32b-instruct:free\n",
            "  ⚠ No hay datos para qwen/qwen2.5-vl-32b-instruct:free - todos los registros con similarity 0\n",
            "  • Similitud: 0.0000 (0/6533)\n",
            "  ⚠ 6533 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.0000\n",
            "    - Procesados: 0\n",
            "    - Errores/omitidos: 6533\n",
            "Evaluando modelo: x-ai/grok-3-mini-beta\n",
            "  ⚠ 280 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3510\n",
            "    - Procesados: 6253\n",
            "    - Errores/omitidos: 280\n",
            "Evaluando modelo: perplexity/sonar\n",
            "  ⚠ 354 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5032\n",
            "    - Procesados: 6179\n",
            "    - Errores/omitidos: 354\n",
            "Evaluando modelo: mistralai/mistral-medium-3\n",
            "  ⚠ 287 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3256\n",
            "    - Procesados: 6246\n",
            "    - Errores/omitidos: 287\n",
            "Evaluando modelo: mistralai/mixtral-8x7b-instruct\n",
            "  ⚠ 299 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3430\n",
            "    - Procesados: 6234\n",
            "    - Errores/omitidos: 299\n",
            "Evaluando modelo: google/gemini-2.5-flash\n",
            "  ⚠ 287 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.4041\n",
            "    - Procesados: 6246\n",
            "    - Errores/omitidos: 287\n",
            "Evaluando modelo: meta-llama/llama-3.1-405b-instruct\n",
            "  ⚠ 702 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3034\n",
            "    - Procesados: 5831\n",
            "    - Errores/omitidos: 702\n",
            "Evaluando modelo: deepseek/deepseek-chat-v3.1\n",
            "  ⚠ 24 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3462\n",
            "    - Procesados: 6509\n",
            "    - Errores/omitidos: 24\n",
            "Evaluando modelo: moonshotai/kimi-k2-0905\n",
            "  ⚠ 2839 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.2022\n",
            "    - Procesados: 3694\n",
            "    - Errores/omitidos: 2839\n",
            "Evaluando modelo: openai/o4-mini-high\n",
            "  ⚠ 3 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3628\n",
            "    - Procesados: 6530\n",
            "    - Errores/omitidos: 3\n",
            "Evaluando modelo: openai/gpt-4.1\n",
            "  ⚠ 10 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3993\n",
            "    - Procesados: 6523\n",
            "    - Errores/omitidos: 10\n",
            "Evaluando modelo: openai/o1-mini\n",
            "  ⚠ 1 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3659\n",
            "    - Procesados: 6532\n",
            "    - Errores/omitidos: 1\n",
            "Evaluando modelo: anthropic/claude-sonnet-4\n",
            "  • Similitud: 0.4054\n",
            "    - Procesados: 6533\n",
            "    - Errores/omitidos: 0\n",
            "Evaluando modelo: gpt-5.1\n",
            "  ⚠ 2 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3946\n",
            "    - Procesados: 6531\n",
            "    - Errores/omitidos: 2\n",
            "\n",
            "RESULTADOS con Sentence-BERT (paraphrase-mpnet):\n",
            "   amazon/nova-micro-v1:\n",
            "      • Similitud: 0.3284 (±0.2013) [6533/6533]\n",
            "   microsoft/phi-4:\n",
            "      • Similitud: 0.2662 (±0.1874) [6533/6533]\n",
            "   amazon/nova-lite-v1:\n",
            "      • Similitud: 0.3363 (±0.2065) [6533/6533]\n",
            "   cohere/command-r-08-2024:\n",
            "      • Similitud: 0.3303 (±0.2205) [6533/6533]\n",
            "   qwen/qwen-2.5-72b-instruct:\n",
            "      • Similitud: 0.3291 (±0.2442) [6533/6533]\n",
            "   google/gemma-2-27b-it:\n",
            "      • Similitud: 0.3116 (±0.2004) [6533/6533]\n",
            "   meta-llama/llama-3.3-70b-instruct:\n",
            "      • Similitud: 0.3451 (±0.2259) [6533/6533]\n",
            "   microsoft/wizardlm-2-8x22b:\n",
            "      • Similitud: 0.3222 (±0.2030) [6533/6533]\n",
            "   meta-llama/llama-4-maverick:\n",
            "      • Similitud: 0.3676 (±0.2411) [6533/6533]\n",
            "   qwen/qwen2.5-vl-32b-instruct:free:\n",
            "      • Similitud: 0.0000 (±0.0000) [13066/6533]\n",
            "   x-ai/grok-3-mini-beta:\n",
            "      • Similitud: 0.3510 (±0.2301) [6533/6533]\n",
            "   perplexity/sonar:\n",
            "      • Similitud: 0.5032 (±0.2812) [6533/6533]\n",
            "   mistralai/mistral-medium-3:\n",
            "      • Similitud: 0.3256 (±0.2297) [6533/6533]\n",
            "   mistralai/mixtral-8x7b-instruct:\n",
            "      • Similitud: 0.3430 (±0.2226) [6533/6533]\n",
            "   google/gemini-2.5-flash:\n",
            "      • Similitud: 0.4041 (±0.2505) [6533/6533]\n",
            "   meta-llama/llama-3.1-405b-instruct:\n",
            "      • Similitud: 0.3034 (±0.2299) [6533/6533]\n",
            "   deepseek/deepseek-chat-v3.1:\n",
            "      • Similitud: 0.3462 (±0.2248) [6533/6533]\n",
            "   moonshotai/kimi-k2-0905:\n",
            "      • Similitud: 0.2022 (±0.2443) [6533/6533]\n",
            "   openai/o4-mini-high:\n",
            "      • Similitud: 0.3628 (±0.2362) [6533/6533]\n",
            "   openai/gpt-4.1:\n",
            "      • Similitud: 0.3993 (±0.2514) [6533/6533]\n",
            "   openai/o1-mini:\n",
            "      • Similitud: 0.3659 (±0.2359) [6533/6533]\n",
            "   anthropic/claude-sonnet-4:\n",
            "      • Similitud: 0.4054 (±0.2525) [6533/6533]\n",
            "   gpt-5.1:\n",
            "      • Similitud: 0.3946 (±0.2447) [6533/6533]\n",
            "\n",
            "✓ Guardado en: /content/drive/MyDrive/LLMs_Metrics/Metrics_Results/prompt_2_paraphrase-mpnet_sbert_similarity_resultados.json\n",
            "\n",
            "============================================================\n",
            "Calculando Sentence-BERT Similarity con XLM-RoBERTa\n",
            "============================================================\n",
            "Evaluando modelo: amazon/nova-micro-v1\n",
            "  ⚠ 12 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.2995\n",
            "    - Procesados: 6521\n",
            "    - Errores/omitidos: 12\n",
            "Evaluando modelo: microsoft/phi-4\n",
            "  ⚠ 381 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.2380\n",
            "    - Procesados: 6152\n",
            "    - Errores/omitidos: 381\n",
            "Evaluando modelo: amazon/nova-lite-v1\n",
            "  ⚠ 75 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3028\n",
            "    - Procesados: 6458\n",
            "    - Errores/omitidos: 75\n",
            "Evaluando modelo: cohere/command-r-08-2024\n",
            "  ⚠ 357 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3109\n",
            "    - Procesados: 6176\n",
            "    - Errores/omitidos: 357\n",
            "Evaluando modelo: qwen/qwen-2.5-72b-instruct\n",
            "  ⚠ 733 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3006\n",
            "    - Procesados: 5800\n",
            "    - Errores/omitidos: 733\n",
            "Evaluando modelo: google/gemma-2-27b-it\n",
            "  ⚠ 153 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.2907\n",
            "    - Procesados: 6380\n",
            "    - Errores/omitidos: 153\n",
            "Evaluando modelo: meta-llama/llama-3.3-70b-instruct\n",
            "  ⚠ 378 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3078\n",
            "    - Procesados: 6155\n",
            "    - Errores/omitidos: 378\n",
            "Evaluando modelo: microsoft/wizardlm-2-8x22b\n",
            "  ⚠ 150 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.2822\n",
            "    - Procesados: 6383\n",
            "    - Errores/omitidos: 150\n",
            "Evaluando modelo: meta-llama/llama-4-maverick\n",
            "  ⚠ 30 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3404\n",
            "    - Procesados: 6503\n",
            "    - Errores/omitidos: 30\n",
            "Evaluando modelo: qwen/qwen2.5-vl-32b-instruct:free\n",
            "  ⚠ No hay datos para qwen/qwen2.5-vl-32b-instruct:free - todos los registros con similarity 0\n",
            "  • Similitud: 0.0000 (0/6533)\n",
            "  ⚠ 6533 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.0000\n",
            "    - Procesados: 0\n",
            "    - Errores/omitidos: 6533\n",
            "Evaluando modelo: x-ai/grok-3-mini-beta\n",
            "  ⚠ 280 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3211\n",
            "    - Procesados: 6253\n",
            "    - Errores/omitidos: 280\n",
            "Evaluando modelo: perplexity/sonar\n",
            "  ⚠ 354 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.4655\n",
            "    - Procesados: 6179\n",
            "    - Errores/omitidos: 354\n",
            "Evaluando modelo: mistralai/mistral-medium-3\n",
            "  ⚠ 287 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.2982\n",
            "    - Procesados: 6246\n",
            "    - Errores/omitidos: 287\n",
            "Evaluando modelo: mistralai/mixtral-8x7b-instruct\n",
            "  ⚠ 299 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3207\n",
            "    - Procesados: 6234\n",
            "    - Errores/omitidos: 299\n",
            "Evaluando modelo: google/gemini-2.5-flash\n",
            "  ⚠ 287 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3795\n",
            "    - Procesados: 6246\n",
            "    - Errores/omitidos: 287\n",
            "Evaluando modelo: meta-llama/llama-3.1-405b-instruct\n",
            "  ⚠ 702 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.2749\n",
            "    - Procesados: 5831\n",
            "    - Errores/omitidos: 702\n",
            "Evaluando modelo: deepseek/deepseek-chat-v3.1\n",
            "  ⚠ 24 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3087\n",
            "    - Procesados: 6509\n",
            "    - Errores/omitidos: 24\n",
            "Evaluando modelo: moonshotai/kimi-k2-0905\n",
            "  ⚠ 2839 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.1757\n",
            "    - Procesados: 3694\n",
            "    - Errores/omitidos: 2839\n",
            "Evaluando modelo: openai/o4-mini-high\n",
            "  ⚠ 3 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3291\n",
            "    - Procesados: 6530\n",
            "    - Errores/omitidos: 3\n",
            "Evaluando modelo: openai/gpt-4.1\n",
            "  ⚠ 10 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3717\n",
            "    - Procesados: 6523\n",
            "    - Errores/omitidos: 10\n",
            "Evaluando modelo: openai/o1-mini\n",
            "  ⚠ 1 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3321\n",
            "    - Procesados: 6532\n",
            "    - Errores/omitidos: 1\n",
            "Evaluando modelo: anthropic/claude-sonnet-4\n",
            "  • Similitud: 0.3724\n",
            "    - Procesados: 6533\n",
            "    - Errores/omitidos: 0\n",
            "Evaluando modelo: gpt-5.1\n",
            "  ⚠ 2 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.3700\n",
            "    - Procesados: 6531\n",
            "    - Errores/omitidos: 2\n",
            "\n",
            "RESULTADOS con Sentence-BERT (XLM-RoBERTa):\n",
            "   amazon/nova-micro-v1:\n",
            "      • Similitud: 0.2995 (±0.2146) [6533/6533]\n",
            "   microsoft/phi-4:\n",
            "      • Similitud: 0.2380 (±0.1945) [6533/6533]\n",
            "   amazon/nova-lite-v1:\n",
            "      • Similitud: 0.3028 (±0.2223) [6533/6533]\n",
            "   cohere/command-r-08-2024:\n",
            "      • Similitud: 0.3109 (±0.2297) [6533/6533]\n",
            "   qwen/qwen-2.5-72b-instruct:\n",
            "      • Similitud: 0.3006 (±0.2481) [6533/6533]\n",
            "   google/gemma-2-27b-it:\n",
            "      • Similitud: 0.2907 (±0.2141) [6533/6533]\n",
            "   meta-llama/llama-3.3-70b-instruct:\n",
            "      • Similitud: 0.3078 (±0.2353) [6533/6533]\n",
            "   microsoft/wizardlm-2-8x22b:\n",
            "      • Similitud: 0.2822 (±0.2149) [6533/6533]\n",
            "   meta-llama/llama-4-maverick:\n",
            "      • Similitud: 0.3404 (±0.2452) [6533/6533]\n",
            "   qwen/qwen2.5-vl-32b-instruct:free:\n",
            "      • Similitud: 0.0000 (±0.0000) [13066/6533]\n",
            "   x-ai/grok-3-mini-beta:\n",
            "      • Similitud: 0.3211 (±0.2450) [6533/6533]\n",
            "   perplexity/sonar:\n",
            "      • Similitud: 0.4655 (±0.2915) [6533/6533]\n",
            "   mistralai/mistral-medium-3:\n",
            "      • Similitud: 0.2982 (±0.2306) [6533/6533]\n",
            "   mistralai/mixtral-8x7b-instruct:\n",
            "      • Similitud: 0.3207 (±0.2268) [6533/6533]\n",
            "   google/gemini-2.5-flash:\n",
            "      • Similitud: 0.3795 (±0.2631) [6533/6533]\n",
            "   meta-llama/llama-3.1-405b-instruct:\n",
            "      • Similitud: 0.2749 (±0.2326) [6533/6533]\n",
            "   deepseek/deepseek-chat-v3.1:\n",
            "      • Similitud: 0.3087 (±0.2339) [6533/6533]\n",
            "   moonshotai/kimi-k2-0905:\n",
            "      • Similitud: 0.1757 (±0.2333) [6533/6533]\n",
            "   openai/o4-mini-high:\n",
            "      • Similitud: 0.3291 (±0.2446) [6533/6533]\n",
            "   openai/gpt-4.1:\n",
            "      • Similitud: 0.3717 (±0.2562) [6533/6533]\n",
            "   openai/o1-mini:\n",
            "      • Similitud: 0.3321 (±0.2449) [6533/6533]\n",
            "   anthropic/claude-sonnet-4:\n",
            "      • Similitud: 0.3724 (±0.2599) [6533/6533]\n",
            "   gpt-5.1:\n",
            "      • Similitud: 0.3700 (±0.2470) [6533/6533]\n",
            "\n",
            "✓ Guardado en: /content/drive/MyDrive/LLMs_Metrics/Metrics_Results/prompt_2_xlm-roberta_sbert_similarity_resultados.json\n",
            "\n",
            "============================================================\n",
            "Calculando chrF Score\n",
            "============================================================\n",
            "Evaluando modelo: amazon/nova-micro-v1\n",
            "  ⚠ 12 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2279\n",
            "    - Procesados: 6521\n",
            "    - Errores/omitidos: 12\n",
            "Evaluando modelo: microsoft/phi-4\n",
            "  ⚠ 381 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2204\n",
            "    - Procesados: 6152\n",
            "    - Errores/omitidos: 381\n",
            "Evaluando modelo: amazon/nova-lite-v1\n",
            "  ⚠ 75 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2017\n",
            "    - Procesados: 6458\n",
            "    - Errores/omitidos: 75\n",
            "Evaluando modelo: cohere/command-r-08-2024\n",
            "  ⚠ 357 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2272\n",
            "    - Procesados: 6176\n",
            "    - Errores/omitidos: 357\n",
            "Evaluando modelo: qwen/qwen-2.5-72b-instruct\n",
            "  ⚠ 733 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2089\n",
            "    - Procesados: 5800\n",
            "    - Errores/omitidos: 733\n",
            "Evaluando modelo: google/gemma-2-27b-it\n",
            "  ⚠ 153 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2099\n",
            "    - Procesados: 6380\n",
            "    - Errores/omitidos: 153\n",
            "Evaluando modelo: meta-llama/llama-3.3-70b-instruct\n",
            "  ⚠ 378 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.1941\n",
            "    - Procesados: 6155\n",
            "    - Errores/omitidos: 378\n",
            "Evaluando modelo: microsoft/wizardlm-2-8x22b\n",
            "  ⚠ 150 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2520\n",
            "    - Procesados: 6383\n",
            "    - Errores/omitidos: 150\n",
            "Evaluando modelo: meta-llama/llama-4-maverick\n",
            "  ⚠ 30 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2470\n",
            "    - Procesados: 6503\n",
            "    - Errores/omitidos: 30\n",
            "Evaluando modelo: qwen/qwen2.5-vl-32b-instruct:free\n",
            "  ⚠ No hay datos para qwen/qwen2.5-vl-32b-instruct:free - todos los registros con chrF 0\n",
            "  • chrF: 0.0000 (0/6533)\n",
            "  ⚠ 6533 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.0000\n",
            "    - Procesados: 0\n",
            "    - Errores/omitidos: 6533\n",
            "Evaluando modelo: x-ai/grok-3-mini-beta\n",
            "  ⚠ 280 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2284\n",
            "    - Procesados: 6253\n",
            "    - Errores/omitidos: 280\n",
            "Evaluando modelo: perplexity/sonar\n",
            "  ⚠ 354 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.3062\n",
            "    - Procesados: 6179\n",
            "    - Errores/omitidos: 354\n",
            "Evaluando modelo: mistralai/mistral-medium-3\n",
            "  ⚠ 287 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2363\n",
            "    - Procesados: 6246\n",
            "    - Errores/omitidos: 287\n",
            "Evaluando modelo: mistralai/mixtral-8x7b-instruct\n",
            "  ⚠ 299 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2350\n",
            "    - Procesados: 6234\n",
            "    - Errores/omitidos: 299\n",
            "Evaluando modelo: google/gemini-2.5-flash\n",
            "  ⚠ 287 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2649\n",
            "    - Procesados: 6246\n",
            "    - Errores/omitidos: 287\n",
            "Evaluando modelo: meta-llama/llama-3.1-405b-instruct\n",
            "  ⚠ 702 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2134\n",
            "    - Procesados: 5831\n",
            "    - Errores/omitidos: 702\n",
            "Evaluando modelo: deepseek/deepseek-chat-v3.1\n",
            "  ⚠ 24 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2609\n",
            "    - Procesados: 6509\n",
            "    - Errores/omitidos: 24\n",
            "Evaluando modelo: moonshotai/kimi-k2-0905\n",
            "  ⚠ 2839 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.1377\n",
            "    - Procesados: 3694\n",
            "    - Errores/omitidos: 2839\n",
            "Evaluando modelo: openai/o4-mini-high\n",
            "  ⚠ 3 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2463\n",
            "    - Procesados: 6530\n",
            "    - Errores/omitidos: 3\n",
            "Evaluando modelo: openai/gpt-4.1\n",
            "  ⚠ 10 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2751\n",
            "    - Procesados: 6523\n",
            "    - Errores/omitidos: 10\n",
            "Evaluando modelo: openai/o1-mini\n",
            "  ⚠ 1 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2469\n",
            "    - Procesados: 6532\n",
            "    - Errores/omitidos: 1\n",
            "Evaluando modelo: anthropic/claude-sonnet-4\n",
            "  • chrF: 0.2757\n",
            "    - Procesados: 6533\n",
            "    - Errores/omitidos: 0\n",
            "Evaluando modelo: gpt-5.1\n",
            "  ⚠ 2 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2855\n",
            "    - Procesados: 6531\n",
            "    - Errores/omitidos: 2\n",
            "\n",
            "RESULTADOS con chrF:\n",
            "   amazon/nova-micro-v1:\n",
            "      • chrF: 0.2279 (±0.0739) [6533/6533]\n",
            "   microsoft/phi-4:\n",
            "      • chrF: 0.2204 (±0.0838) [6533/6533]\n",
            "   amazon/nova-lite-v1:\n",
            "      • chrF: 0.2017 (±0.0798) [6533/6533]\n",
            "   cohere/command-r-08-2024:\n",
            "      • chrF: 0.2272 (±0.0939) [6533/6533]\n",
            "   qwen/qwen-2.5-72b-instruct:\n",
            "      • chrF: 0.2089 (±0.1133) [6533/6533]\n",
            "   google/gemma-2-27b-it:\n",
            "      • chrF: 0.2099 (±0.0831) [6533/6533]\n",
            "   meta-llama/llama-3.3-70b-instruct:\n",
            "      • chrF: 0.1941 (±0.1012) [6533/6533]\n",
            "   microsoft/wizardlm-2-8x22b:\n",
            "      • chrF: 0.2520 (±0.0900) [6533/6533]\n",
            "   meta-llama/llama-4-maverick:\n",
            "      • chrF: 0.2470 (±0.0971) [6533/6533]\n",
            "   qwen/qwen2.5-vl-32b-instruct:free:\n",
            "      • chrF: 0.0000 (±0.0000) [13066/6533]\n",
            "   x-ai/grok-3-mini-beta:\n",
            "      • chrF: 0.2284 (±0.1007) [6533/6533]\n",
            "   perplexity/sonar:\n",
            "      • chrF: 0.3062 (±0.1673) [6533/6533]\n",
            "   mistralai/mistral-medium-3:\n",
            "      • chrF: 0.2363 (±0.0962) [6533/6533]\n",
            "   mistralai/mixtral-8x7b-instruct:\n",
            "      • chrF: 0.2350 (±0.0980) [6533/6533]\n",
            "   google/gemini-2.5-flash:\n",
            "      • chrF: 0.2649 (±0.1186) [6533/6533]\n",
            "   meta-llama/llama-3.1-405b-instruct:\n",
            "      • chrF: 0.2134 (±0.1087) [6533/6533]\n",
            "   deepseek/deepseek-chat-v3.1:\n",
            "      • chrF: 0.2609 (±0.0902) [6533/6533]\n",
            "   moonshotai/kimi-k2-0905:\n",
            "      • chrF: 0.1377 (±0.1372) [6533/6533]\n",
            "   openai/o4-mini-high:\n",
            "      • chrF: 0.2463 (±0.0857) [6533/6533]\n",
            "   openai/gpt-4.1:\n",
            "      • chrF: 0.2751 (±0.0952) [6533/6533]\n",
            "   openai/o1-mini:\n",
            "      • chrF: 0.2469 (±0.0855) [6533/6533]\n",
            "   anthropic/claude-sonnet-4:\n",
            "      • chrF: 0.2757 (±0.1078) [6533/6533]\n",
            "   gpt-5.1:\n",
            "      • chrF: 0.2855 (±0.0915) [6533/6533]\n",
            "\n",
            "✓ Guardado en: /content/drive/MyDrive/LLMs_Metrics/Metrics_Results/prompt_2_chrf_resultados.json\n",
            "\n",
            "================================================================================\n",
            "PROMPT 2 COMPLETADO\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('CodeMetrics') # Ensure CodeMetrics is in path for imports\n",
        "from SentenceBert import compute_scibeto_similarity # Explicitly import here\n",
        "from BertScore import compute_bertscore_beto, compute_bertscore_sci_beto # Explicitly import BERTScore functions\n",
        "from SentenceBert import compute_sbert_similarity, compute_xlm_similarity # And these for consistency\n",
        "from chrF import compute_chrf_batch\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"PROMPT 2: Modismo → Definición\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"Objetivo: Evaluar si el modelo puede generar una definición correcta del modismo\")\n",
        "print(\"Métricas:\")\n",
        "print(\"  - BERTScore (BETO y SciBETO): Similitud semántica con embeddings de BERT\")\n",
        "print(\"  - Sentence-BERT: Similitud con modelo multilingüe paraphrase-mpnet\")\n",
        "print(\"  - chrF: Character n-gram F-score\")\n",
        "print(\"Nota: Los errores/omisiones se cuentan con score 0 en todas las métricas.\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Cargar datos desde JSON\n",
        "with open(os.path.join(DATA_DIR, 'prompt_2_metrics_data.json'), 'r', encoding='utf-8') as f:\n",
        "    data_p2 = json.load(f)\n",
        "\n",
        "# Filtrar datos vacíos\n",
        "data_p2_valid = [d for d in data_p2 if d.get('definicion_real') and d.get('definicion_generada')]\n",
        "print(f\"Datos cargados: {len(data_p2_valid)} registros válidos de {len(data_p2)} totales\")\n",
        "print()\n",
        "\n",
        "# ============================================================================\n",
        "# 1. BERTScore con BETO y SciBETO\n",
        "# ============================================================================\n",
        "bert_models = [\n",
        "    ('BETO', compute_bertscore_beto),\n",
        "    ('SciBETO', compute_bertscore_sci_beto)\n",
        "]\n",
        "\n",
        "for bert_name, bert_func in bert_models:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Calculando BERTScore con {bert_name}\")\n",
        "    print('='*60)\n",
        "\n",
        "    resultados_p2 = []\n",
        "\n",
        "    for model in MODEL_NAMES:\n",
        "        print(f\"Evaluando modelo: {model}\")\n",
        "\n",
        "        # Filtrar datos de este modelo\n",
        "        model_data = [d for d in data_p2_valid if d.get('modelo') == model]\n",
        "\n",
        "        if not model_data:\n",
        "            print(f\"  ⚠ No hay datos para {model} - todos los registros con score 0\")\n",
        "            # Agregar todos los registros con score 0\n",
        "            for _ in range(GROUNTH_TRUTH):\n",
        "                resultados_p2.append({\n",
        "                    'modismo': 'N/A',\n",
        "                    'modelo': model,\n",
        "                    'bert_model': bert_name,\n",
        "                    'precision': 0.0,\n",
        "                    'recall': 0.0,\n",
        "                    'f1_score': 0.0,\n",
        "                    'definicion_real': '',\n",
        "                    'definicion_generada': ''\n",
        "                })\n",
        "            print(f\"  • F1 Score: 0.0000 (0/{GROUNTH_TRUTH})\")\n",
        "        else:\n",
        "            referencias = [d['definicion_real'] for d in model_data]\n",
        "            candidatos = [d['definicion_generada'] for d in model_data]\n",
        "\n",
        "            # BERTScore: compara candidatos (generados) vs referencias (reales)\n",
        "            P, R, F1 = bert_func(candidatos, referencias)\n",
        "\n",
        "            for idx, (p, r, f1) in enumerate(zip(P.tolist(), R.tolist(), F1.tolist())):\n",
        "                resultados_p2.append({\n",
        "                    'modismo': model_data[idx]['modismo'],\n",
        "                    'modelo': model,\n",
        "                    'bert_model': bert_name,\n",
        "                    'precision': p,\n",
        "                    'recall': r,\n",
        "                    'f1_score': f1,\n",
        "                    'definicion_real': referencias[idx],\n",
        "                    'definicion_generada': candidatos[idx]\n",
        "                })\n",
        "\n",
        "        # Calcular registros faltantes (omitidos por errores)\n",
        "        registros_procesados = len(model_data)\n",
        "        registros_faltantes = GROUNTH_TRUTH - registros_procesados\n",
        "\n",
        "        # Agregar registros faltantes con score 0\n",
        "        if registros_faltantes > 0:\n",
        "            print(f\"  ⚠ {registros_faltantes} registros omitidos se cuentan con score 0\")\n",
        "            for _ in range(registros_faltantes):\n",
        "                resultados_p2.append({\n",
        "                    'modismo': 'ERROR/OMITIDO',\n",
        "                    'modelo': model,\n",
        "                    'bert_model': bert_name,\n",
        "                    'precision': 0.0,\n",
        "                    'recall': 0.0,\n",
        "                    'f1_score': 0.0,\n",
        "                    'definicion_real': '',\n",
        "                    'definicion_generada': ''\n",
        "                })\n",
        "\n",
        "        # Calcular promedios sobre el total (GROUNTH_TRUTH) for the *current* model\n",
        "        all_f1_scores = [r['f1_score'] for r in resultados_p2 if r['modelo'] == model and r['bert_model'] == bert_name]\n",
        "        all_precisions = [r['precision'] for r in resultados_p2 if r['modelo'] == model and r['bert_model'] == bert_name]\n",
        "        all_recalls = [r['recall'] for r in resultados_p2 if r['modelo'] == model and r['bert_model'] == bert_name]\n",
        "\n",
        "        f1_mean = np.mean(all_f1_scores)\n",
        "        p_mean = np.mean(all_precisions)\n",
        "        r_mean = np.mean(all_recalls)\n",
        "\n",
        "        print(f\"  • Precision: {p_mean:.4f}\")\n",
        "        print(f\"  • Recall:    {r_mean:.4f}\")\n",
        "        print(f\"  • F1 Score:  {f1_mean:.4f}\")\n",
        "        print(f\"    - Procesados: {registros_procesados}\")\n",
        "        print(f\"    - Errores/omitidos: {registros_faltantes}\")\n",
        "\n",
        "    # Guardar resultados\n",
        "    output_file = os.path.join(OUTPUT_DIR, f'prompt_2_{bert_name.lower()}_bertscore_resultados.json')\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(resultados_p2, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print()\n",
        "    print(f\"RESULTADOS con {bert_name}:\")\n",
        "    for model in MODEL_NAMES:\n",
        "        model_results = [r for r in resultados_p2 if r['modelo'] == model]\n",
        "        if model_results:\n",
        "            f1_scores = [r['f1_score'] for r in model_results]\n",
        "            precisions = [r['precision'] for r in model_results]\n",
        "            recalls = [r['recall'] for r in model_results]\n",
        "\n",
        "            f1_mean = np.mean(f1_scores)\n",
        "            f1_std = np.std(f1_scores)\n",
        "            p_mean = np.mean(precisions)\n",
        "            r_mean = np.mean(recalls)\n",
        "\n",
        "            print(f\"   {model}:\")\n",
        "            print(f\"      • Precision: {p_mean:.4f}\")\n",
        "            print(f\"      • Recall:    {r_mean:.4f}\")\n",
        "            print(f\"      • F1 Score:  {f1_mean:.4f} (±{f1_std:.4f}) [{len(model_results)}/{GROUNTH_TRUTH}]\")\n",
        "\n",
        "    print(f\"\\n✓ Guardado en: {output_file}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. Sentence-BERT Similarity\n",
        "# ============================================================================\n",
        "sbert_models = [\n",
        "    ('SciBETO-mean', compute_scibeto_similarity),\n",
        "    ('paraphrase-mpnet', compute_sbert_similarity),\n",
        "    ('XLM-RoBERTa', compute_xlm_similarity)\n",
        "]\n",
        "\n",
        "for sbert_name, sbert_func in sbert_models:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Calculando Sentence-BERT Similarity con {sbert_name}\")\n",
        "    print('='*60)\n",
        "\n",
        "    resultados_sbert = []\n",
        "\n",
        "    for model in MODEL_NAMES:\n",
        "        print(f\"Evaluando modelo: {model}\")\n",
        "\n",
        "        model_data = [d for d in data_p2_valid if d.get('modelo') == model]\n",
        "\n",
        "        if not model_data:\n",
        "            print(f\"  ⚠ No hay datos para {model} - todos los registros con similarity 0\")\n",
        "            # Agregar todos los registros con similarity 0\n",
        "            for _ in range(GROUNTH_TRUTH):\n",
        "                resultados_sbert.append({\n",
        "                    'modismo': 'N/A',\n",
        "                    'modelo': model,\n",
        "                    'sbert_model': sbert_name,\n",
        "                    'similarity': 0.0,\n",
        "                    'definicion_real': '',\n",
        "                    'definicion_generada': ''\n",
        "                })\n",
        "            print(f\"  • Similitud: 0.0000 (0/{GROUNTH_TRUTH})\")\n",
        "        else:\n",
        "            referencias = [d['definicion_real'] for d in model_data]\n",
        "            candidatos = [d['definicion_generada'] for d in model_data]\n",
        "\n",
        "            # Calcular similitud con Sentence-BERT\n",
        "            similarities = sbert_func(candidatos, referencias)\n",
        "\n",
        "            for idx, sim in enumerate(similarities):\n",
        "                resultados_sbert.append({\n",
        "                    'modismo': model_data[idx]['modismo'],\n",
        "                    'modelo': model,\n",
        "                    'sbert_model': sbert_name,\n",
        "                    'similarity': float(sim),\n",
        "                    'definicion_real': referencias[idx],\n",
        "                    'definicion_generada': candidatos[idx]\n",
        "                })\n",
        "\n",
        "        # Calcular registros faltantes (omitidos por errores)\n",
        "        registros_procesados = len(model_data)\n",
        "        registros_faltantes = GROUNTH_TRUTH - registros_procesados\n",
        "\n",
        "        # Agregar registros faltantes con similarity 0\n",
        "        if registros_faltantes > 0:\n",
        "            print(f\"  ⚠ {registros_faltantes} registros omitidos se cuentan con similarity 0\")\n",
        "            for _ in range(registros_faltantes):\n",
        "                resultados_sbert.append({\n",
        "                    'modismo': 'ERROR/OMITIDO',\n",
        "                    'modelo': model,\n",
        "                    'sbert_model': sbert_name,\n",
        "                    'similarity': 0.0,\n",
        "                    'definicion_real': '',\n",
        "                    'definicion_generada': ''\n",
        "                })\n",
        "\n",
        "        # Calcular promedio sobre el total (GROUNTH_TRUTH)\n",
        "        all_similarities = [r['similarity'] for r in resultados_sbert if r['modelo'] == model and r['sbert_model'] == sbert_name]\n",
        "        sim_mean = np.mean(all_similarities)\n",
        "\n",
        "        print(f\"  • Similitud: {sim_mean:.4f}\")\n",
        "        print(f\"    - Procesados: {registros_procesados}\")\n",
        "        print(f\"    - Errores/omitidos: {registros_faltantes}\")\n",
        "\n",
        "    # Guardar resultados\n",
        "    output_file = os.path.join(OUTPUT_DIR, f'prompt_2_{sbert_name.lower()}_sbert_similarity_resultados.json')\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(resultados_sbert, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print()\n",
        "    print(f\"RESULTADOS con Sentence-BERT ({sbert_name}):\")\n",
        "    for model in MODEL_NAMES:\n",
        "        model_results = [r for r in resultados_sbert if r['modelo'] == model]\n",
        "        if model_results:\n",
        "            similarities = [r['similarity'] for r in model_results]\n",
        "            sim_mean = np.mean(similarities)\n",
        "            sim_std = np.std(similarities)\n",
        "\n",
        "            print(f\"   {model}:\")\n",
        "            print(f\"      • Similitud: {sim_mean:.4f} (±{sim_std:.4f}) [{len(model_results)}/{GROUNTH_TRUTH}]\")\n",
        "\n",
        "    print(f\"\\n✓ Guardado en: {output_file}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 3. chrF Score\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Calculando chrF Score\")\n",
        "print('='*60)\n",
        "\n",
        "resultados_chrf = []\n",
        "\n",
        "for model in MODEL_NAMES:\n",
        "    print(f\"Evaluando modelo: {model}\")\n",
        "\n",
        "    model_data = [d for d in data_p2_valid if d.get('modelo') == model]\n",
        "\n",
        "    if not model_data:\n",
        "        print(f\"  ⚠ No hay datos para {model} - todos los registros con chrF 0\")\n",
        "        # Agregar todos los registros con chrF 0\n",
        "        for _ in range(GROUNTH_TRUTH):\n",
        "            resultados_chrf.append({\n",
        "                'modismo': 'N/A',\n",
        "                'modelo': model,\n",
        "                'chrf_score': 0.0,\n",
        "                'definicion_real': '',\n",
        "                'definicion_generada': ''\n",
        "            })\n",
        "        print(f\"  • chrF: 0.0000 (0/{GROUNTH_TRUTH})\")\n",
        "    else:\n",
        "        referencias = [d['definicion_real'] for d in model_data]\n",
        "        candidatos = [d['definicion_generada'] for d in model_data]\n",
        "\n",
        "        # Calcular chrF\n",
        "        chrf_scores = compute_chrf_batch(candidatos, referencias)\n",
        "\n",
        "        for idx, score in enumerate(chrf_scores):\n",
        "            resultados_chrf.append({\n",
        "                'modismo': model_data[idx]['modismo'],\n",
        "                'modelo': model,\n",
        "                'chrf_score': float(score),\n",
        "                'definicion_real': referencias[idx],\n",
        "                'definicion_generada': candidatos[idx]\n",
        "            })\n",
        "\n",
        "    # Calcular registros faltantes (omitidos por errores)\n",
        "    registros_procesados = len(model_data)\n",
        "    registros_faltantes = GROUNTH_TRUTH - registros_procesados\n",
        "\n",
        "    # Agregar registros faltantes con chrF 0\n",
        "    if registros_faltantes > 0:\n",
        "        print(f\"  ⚠ {registros_faltantes} registros omitidos se cuentan con chrF 0\")\n",
        "        for _ in range(registros_faltantes):\n",
        "            resultados_chrf.append({\n",
        "                'modismo': 'ERROR/OMITIDO',\n",
        "                'modelo': model,\n",
        "                'chrf_score': 0.0,\n",
        "                'definicion_real': '',\n",
        "                'definicion_generada': ''\n",
        "            })\n",
        "\n",
        "    # Calcular promedio sobre el total (GROUNTH_TRUTH)\n",
        "    all_chrf_scores = [r['chrf_score'] for r in resultados_chrf if r['modelo'] == model]\n",
        "    chrf_mean = np.mean(all_chrf_scores)\n",
        "\n",
        "    print(f\"  • chrF: {chrf_mean:.4f}\")\n",
        "    print(f\"    - Procesados: {registros_procesados}\")\n",
        "    print(f\"    - Errores/omitidos: {registros_faltantes}\")\n",
        "\n",
        "# Guardar resultados\n",
        "output_file = os.path.join(OUTPUT_DIR, 'prompt_2_chrf_resultados.json')\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(resultados_chrf, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print()\n",
        "print(\"RESULTADOS con chrF:\")\n",
        "for model in MODEL_NAMES:\n",
        "    model_results = [r for r in resultados_chrf if r['modelo'] == model]\n",
        "    if model_results:\n",
        "        chrf_scores = [r['chrf_score'] for r in model_results]\n",
        "        chrf_mean = np.mean(chrf_scores)\n",
        "        chrf_std = np.std(chrf_scores)\n",
        "\n",
        "        print(f\"   {model}:\")\n",
        "        print(f\"      • chrF: {chrf_mean:.4f} (±{chrf_std:.4f}) [{len(model_results)}/{GROUNTH_TRUTH}]\")\n",
        "\n",
        "print(f\"\\n✓ Guardado en: {output_file}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PROMPT 2 COMPLETADO\")\n",
        "print(\"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a03bb355",
      "metadata": {
        "id": "a03bb355"
      },
      "source": [
        "## 3. PROMPT 3: Modismo + Ejemplo → Literal + Definición"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8d25862e",
      "metadata": {
        "id": "8d25862e"
      },
      "outputs": [],
      "source": [
        "GROUNTH_TRUTH = 4_897"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1d89e4da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d89e4da",
        "outputId": "504f276f-7a7b-4ea3-ba47-67136e870304"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "PROMPT 3: Modismo + Ejemplo → Literal + Definición\n",
            "================================================================================\n",
            "Objetivo: Evaluar si el modelo genera interpretaciones literales correctas\n",
            "Métricas:\n",
            "  - BERTScore (BETO y SciBETO): Similitud semántica con embeddings de BERT\n",
            "  - Sentence-BERT: Similitud con modelo multilingüe paraphrase-mpnet\n",
            "  - chrF: Character n-gram F-score\n",
            "Nota: Los errores/omisiones se cuentan con score 0 en todas las métricas.\n",
            "--------------------------------------------------------------------------------\n",
            "Datos cargados: 98961 registros válidos de 99507 totales\n",
            "\n",
            "\n",
            "============================================================\n",
            "Calculando BERTScore con BETO\n",
            "============================================================\n",
            "Evaluando modelo: amazon/nova-micro-v1\n",
            "  ⚠ 55 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4628\n",
            "  • Recall:    0.4348\n",
            "  • F1 Score:  0.4473\n",
            "    - Procesados: 4842\n",
            "    - Errores/omitidos: 55\n",
            "Evaluando modelo: microsoft/phi-4\n",
            "  ⚠ 51 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4718\n",
            "  • Recall:    0.4792\n",
            "  • F1 Score:  0.4743\n",
            "    - Procesados: 4846\n",
            "    - Errores/omitidos: 51\n",
            "Evaluando modelo: amazon/nova-lite-v1\n",
            "  ⚠ 21 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.5089\n",
            "  • Recall:    0.4996\n",
            "  • F1 Score:  0.5031\n",
            "    - Procesados: 4876\n",
            "    - Errores/omitidos: 21\n",
            "Evaluando modelo: cohere/command-r-08-2024\n",
            "  ⚠ 62 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.5122\n",
            "  • Recall:    0.5102\n",
            "  • F1 Score:  0.5101\n",
            "    - Procesados: 4835\n",
            "    - Errores/omitidos: 62\n",
            "Evaluando modelo: qwen/qwen-2.5-72b-instruct\n",
            "  ⚠ 570 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4563\n",
            "  • Recall:    0.4318\n",
            "  • F1 Score:  0.4427\n",
            "    - Procesados: 4327\n",
            "    - Errores/omitidos: 570\n",
            "Evaluando modelo: google/gemma-2-27b-it\n",
            "  ⚠ 86 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4892\n",
            "  • Recall:    0.4634\n",
            "  • F1 Score:  0.4748\n",
            "    - Procesados: 4811\n",
            "    - Errores/omitidos: 86\n",
            "Evaluando modelo: meta-llama/llama-3.3-70b-instruct\n",
            "  ⚠ 120 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4741\n",
            "  • Recall:    0.4407\n",
            "  • F1 Score:  0.4557\n",
            "    - Procesados: 4777\n",
            "    - Errores/omitidos: 120\n",
            "Evaluando modelo: microsoft/wizardlm-2-8x22b\n",
            "  ⚠ No hay datos para microsoft/wizardlm-2-8x22b - todos los registros con score 0\n",
            "  • F1 Score: 0.0000 (0/4897)\n",
            "Evaluando modelo: meta-llama/llama-4-maverick\n",
            "  ⚠ 28 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.5201\n",
            "  • Recall:    0.4979\n",
            "  • F1 Score:  0.5076\n",
            "    - Procesados: 4869\n",
            "    - Errores/omitidos: 28\n",
            "Evaluando modelo: qwen/qwen2.5-vl-32b-instruct:free\n",
            "  ⚠ No hay datos para qwen/qwen2.5-vl-32b-instruct:free - todos los registros con score 0\n",
            "  • F1 Score: 0.0000 (0/4897)\n",
            "Evaluando modelo: x-ai/grok-3-mini-beta\n",
            "  ⚠ 291 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4807\n",
            "  • Recall:    0.4647\n",
            "  • F1 Score:  0.4716\n",
            "    - Procesados: 4606\n",
            "    - Errores/omitidos: 291\n",
            "Evaluando modelo: perplexity/sonar\n",
            "  ⚠ 3 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.5560\n",
            "  • Recall:    0.5444\n",
            "  • F1 Score:  0.5490\n",
            "    - Procesados: 4894\n",
            "    - Errores/omitidos: 3\n",
            "Evaluando modelo: mistralai/mistral-medium-3\n",
            "  ⚠ 154 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.5247\n",
            "  • Recall:    0.5144\n",
            "  • F1 Score:  0.5184\n",
            "    - Procesados: 4743\n",
            "    - Errores/omitidos: 154\n",
            "Evaluando modelo: mistralai/mixtral-8x7b-instruct\n",
            "  ⚠ 396 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4504\n",
            "  • Recall:    0.4530\n",
            "  • F1 Score:  0.4506\n",
            "    - Procesados: 4501\n",
            "    - Errores/omitidos: 396\n",
            "Evaluando modelo: google/gemini-2.5-flash\n",
            "  ⚠ 295 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.5179\n",
            "  • Recall:    0.4986\n",
            "  • F1 Score:  0.5070\n",
            "    - Procesados: 4602\n",
            "    - Errores/omitidos: 295\n",
            "Evaluando modelo: meta-llama/llama-3.1-405b-instruct\n",
            "  ⚠ 445 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4688\n",
            "  • Recall:    0.4606\n",
            "  • F1 Score:  0.4635\n",
            "    - Procesados: 4452\n",
            "    - Errores/omitidos: 445\n",
            "Evaluando modelo: deepseek/deepseek-chat-v3.1\n",
            "  ⚠ 324 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.5013\n",
            "  • Recall:    0.4998\n",
            "  • F1 Score:  0.4995\n",
            "    - Procesados: 4573\n",
            "    - Errores/omitidos: 324\n",
            "Evaluando modelo: moonshotai/kimi-k2-0905\n",
            "  ⚠ 638 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.4605\n",
            "  • Recall:    0.4473\n",
            "  • F1 Score:  0.4529\n",
            "    - Procesados: 4259\n",
            "    - Errores/omitidos: 638\n",
            "Evaluando modelo: openai/o4-mini-high\n",
            "  ⚠ 160 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.5047\n",
            "  • Recall:    0.4866\n",
            "  • F1 Score:  0.4944\n",
            "    - Procesados: 4737\n",
            "    - Errores/omitidos: 160\n",
            "Evaluando modelo: openai/gpt-4.1\n",
            "  ⚠ 18 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.5405\n",
            "  • Recall:    0.5188\n",
            "  • F1 Score:  0.5283\n",
            "    - Procesados: 4879\n",
            "    - Errores/omitidos: 18\n",
            "Evaluando modelo: openai/o1-mini\n",
            "  ⚠ 6 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.5219\n",
            "  • Recall:    0.5022\n",
            "  • F1 Score:  0.5108\n",
            "    - Procesados: 4891\n",
            "    - Errores/omitidos: 6\n",
            "Evaluando modelo: anthropic/claude-sonnet-4\n",
            "  ⚠ 149 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.5301\n",
            "  • Recall:    0.5332\n",
            "  • F1 Score:  0.5306\n",
            "    - Procesados: 4748\n",
            "    - Errores/omitidos: 149\n",
            "Evaluando modelo: gpt-5.1\n",
            "  ⚠ 4 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.5480\n",
            "  • Recall:    0.5417\n",
            "  • F1 Score:  0.5436\n",
            "    - Procesados: 4893\n",
            "    - Errores/omitidos: 4\n",
            "\n",
            "RESULTADOS con BETO:\n",
            "   amazon/nova-micro-v1:\n",
            "      • Precision: 0.4628\n",
            "      • Recall:    0.4348\n",
            "      • F1 Score:  0.4473 (±0.1083) [4897/4897]\n",
            "   microsoft/phi-4:\n",
            "      • Precision: 0.4718\n",
            "      • Recall:    0.4792\n",
            "      • F1 Score:  0.4743 (±0.1089) [4897/4897]\n",
            "   amazon/nova-lite-v1:\n",
            "      • Precision: 0.5089\n",
            "      • Recall:    0.4996\n",
            "      • F1 Score:  0.5031 (±0.1035) [4897/4897]\n",
            "   cohere/command-r-08-2024:\n",
            "      • Precision: 0.5122\n",
            "      • Recall:    0.5102\n",
            "      • F1 Score:  0.5101 (±0.1150) [4897/4897]\n",
            "   qwen/qwen-2.5-72b-instruct:\n",
            "      • Precision: 0.4563\n",
            "      • Recall:    0.4318\n",
            "      • F1 Score:  0.4427 (±0.1895) [4897/4897]\n",
            "   google/gemma-2-27b-it:\n",
            "      • Precision: 0.4892\n",
            "      • Recall:    0.4634\n",
            "      • F1 Score:  0.4748 (±0.1217) [4897/4897]\n",
            "   meta-llama/llama-3.3-70b-instruct:\n",
            "      • Precision: 0.4741\n",
            "      • Recall:    0.4407\n",
            "      • F1 Score:  0.4557 (±0.1244) [4897/4897]\n",
            "   microsoft/wizardlm-2-8x22b:\n",
            "      • Precision: 0.0000\n",
            "      • Recall:    0.0000\n",
            "      • F1 Score:  0.0000 (±0.0000) [4897/4897]\n",
            "   meta-llama/llama-4-maverick:\n",
            "      • Precision: 0.5201\n",
            "      • Recall:    0.4979\n",
            "      • F1 Score:  0.5076 (±0.1125) [4897/4897]\n",
            "   qwen/qwen2.5-vl-32b-instruct:free:\n",
            "      • Precision: 0.0000\n",
            "      • Recall:    0.0000\n",
            "      • F1 Score:  0.0000 (±0.0000) [4897/4897]\n",
            "   x-ai/grok-3-mini-beta:\n",
            "      • Precision: 0.4807\n",
            "      • Recall:    0.4647\n",
            "      • F1 Score:  0.4716 (±0.1546) [4897/4897]\n",
            "   perplexity/sonar:\n",
            "      • Precision: 0.5560\n",
            "      • Recall:    0.5444\n",
            "      • F1 Score:  0.5490 (±0.1123) [4897/4897]\n",
            "   mistralai/mistral-medium-3:\n",
            "      • Precision: 0.5247\n",
            "      • Recall:    0.5144\n",
            "      • F1 Score:  0.5184 (±0.1385) [4897/4897]\n",
            "   mistralai/mixtral-8x7b-instruct:\n",
            "      • Precision: 0.4504\n",
            "      • Recall:    0.4530\n",
            "      • F1 Score:  0.4506 (±0.1649) [4897/4897]\n",
            "   google/gemini-2.5-flash:\n",
            "      • Precision: 0.5179\n",
            "      • Recall:    0.4986\n",
            "      • F1 Score:  0.5070 (±0.1630) [4897/4897]\n",
            "   meta-llama/llama-3.1-405b-instruct:\n",
            "      • Precision: 0.4688\n",
            "      • Recall:    0.4606\n",
            "      • F1 Score:  0.4635 (±0.1772) [4897/4897]\n",
            "   deepseek/deepseek-chat-v3.1:\n",
            "      • Precision: 0.5013\n",
            "      • Recall:    0.4998\n",
            "      • F1 Score:  0.4995 (±0.1683) [4897/4897]\n",
            "   moonshotai/kimi-k2-0905:\n",
            "      • Precision: 0.4605\n",
            "      • Recall:    0.4473\n",
            "      • F1 Score:  0.4529 (±0.2013) [4897/4897]\n",
            "   openai/o4-mini-high:\n",
            "      • Precision: 0.5047\n",
            "      • Recall:    0.4866\n",
            "      • F1 Score:  0.4944 (±0.1409) [4897/4897]\n",
            "   openai/gpt-4.1:\n",
            "      • Precision: 0.5405\n",
            "      • Recall:    0.5188\n",
            "      • F1 Score:  0.5283 (±0.1104) [4897/4897]\n",
            "   openai/o1-mini:\n",
            "      • Precision: 0.5219\n",
            "      • Recall:    0.5022\n",
            "      • F1 Score:  0.5108 (±0.1086) [4897/4897]\n",
            "   anthropic/claude-sonnet-4:\n",
            "      • Precision: 0.5301\n",
            "      • Recall:    0.5332\n",
            "      • F1 Score:  0.5306 (±0.1418) [4897/4897]\n",
            "   gpt-5.1:\n",
            "      • Precision: 0.5480\n",
            "      • Recall:    0.5417\n",
            "      • F1 Score:  0.5436 (±0.1026) [4897/4897]\n",
            "\n",
            "✓ Guardado en: /content/drive/MyDrive/LLMs_Metrics/Metrics_Results/prompt_3_beto_bertscore_resultados.json\n",
            "\n",
            "============================================================\n",
            "Calculando BERTScore con SciBETO\n",
            "============================================================\n",
            "Evaluando modelo: amazon/nova-micro-v1\n",
            "  ⚠ 55 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7277\n",
            "  • Recall:    0.7183\n",
            "  • F1 Score:  0.7226\n",
            "    - Procesados: 4842\n",
            "    - Errores/omitidos: 55\n",
            "Evaluando modelo: microsoft/phi-4\n",
            "  ⚠ 51 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7301\n",
            "  • Recall:    0.7386\n",
            "  • F1 Score:  0.7340\n",
            "    - Procesados: 4846\n",
            "    - Errores/omitidos: 51\n",
            "Evaluando modelo: amazon/nova-lite-v1\n",
            "  ⚠ 21 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7633\n",
            "  • Recall:    0.7549\n",
            "  • F1 Score:  0.7586\n",
            "    - Procesados: 4876\n",
            "    - Errores/omitidos: 21\n",
            "Evaluando modelo: cohere/command-r-08-2024\n",
            "  ⚠ 62 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7580\n",
            "  • Recall:    0.7534\n",
            "  • F1 Score:  0.7553\n",
            "    - Procesados: 4835\n",
            "    - Errores/omitidos: 62\n",
            "Evaluando modelo: qwen/qwen-2.5-72b-instruct\n",
            "  ⚠ 570 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.6765\n",
            "  • Recall:    0.6608\n",
            "  • F1 Score:  0.6681\n",
            "    - Procesados: 4327\n",
            "    - Errores/omitidos: 570\n",
            "Evaluando modelo: google/gemma-2-27b-it\n",
            "  ⚠ 86 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7455\n",
            "  • Recall:    0.7285\n",
            "  • F1 Score:  0.7364\n",
            "    - Procesados: 4811\n",
            "    - Errores/omitidos: 86\n",
            "Evaluando modelo: meta-llama/llama-3.3-70b-instruct\n",
            "  ⚠ 120 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7282\n",
            "  • Recall:    0.7119\n",
            "  • F1 Score:  0.7195\n",
            "    - Procesados: 4777\n",
            "    - Errores/omitidos: 120\n",
            "Evaluando modelo: microsoft/wizardlm-2-8x22b\n",
            "  ⚠ No hay datos para microsoft/wizardlm-2-8x22b - todos los registros con score 0\n",
            "  • F1 Score: 0.0000 (0/4897)\n",
            "Evaluando modelo: meta-llama/llama-4-maverick\n",
            "  ⚠ 28 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7538\n",
            "  • Recall:    0.7442\n",
            "  • F1 Score:  0.7485\n",
            "    - Procesados: 4869\n",
            "    - Errores/omitidos: 28\n",
            "Evaluando modelo: qwen/qwen2.5-vl-32b-instruct:free\n",
            "  ⚠ No hay datos para qwen/qwen2.5-vl-32b-instruct:free - todos los registros con score 0\n",
            "  • F1 Score: 0.0000 (0/4897)\n",
            "Evaluando modelo: x-ai/grok-3-mini-beta\n",
            "  ⚠ 291 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7110\n",
            "  • Recall:    0.7043\n",
            "  • F1 Score:  0.7072\n",
            "    - Procesados: 4606\n",
            "    - Errores/omitidos: 291\n",
            "Evaluando modelo: perplexity/sonar\n",
            "  ⚠ 3 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7713\n",
            "  • Recall:    0.7673\n",
            "  • F1 Score:  0.7688\n",
            "    - Procesados: 4894\n",
            "    - Errores/omitidos: 3\n",
            "Evaluando modelo: mistralai/mistral-medium-3\n",
            "  ⚠ 154 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7598\n",
            "  • Recall:    0.7468\n",
            "  • F1 Score:  0.7528\n",
            "    - Procesados: 4743\n",
            "    - Errores/omitidos: 154\n",
            "Evaluando modelo: mistralai/mixtral-8x7b-instruct\n",
            "  ⚠ 396 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.6734\n",
            "  • Recall:    0.6811\n",
            "  • F1 Score:  0.6769\n",
            "    - Procesados: 4501\n",
            "    - Errores/omitidos: 396\n",
            "Evaluando modelo: google/gemini-2.5-flash\n",
            "  ⚠ 295 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7406\n",
            "  • Recall:    0.7221\n",
            "  • F1 Score:  0.7307\n",
            "    - Procesados: 4602\n",
            "    - Errores/omitidos: 295\n",
            "Evaluando modelo: meta-llama/llama-3.1-405b-instruct\n",
            "  ⚠ 445 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.6883\n",
            "  • Recall:    0.6860\n",
            "  • F1 Score:  0.6867\n",
            "    - Procesados: 4452\n",
            "    - Errores/omitidos: 445\n",
            "Evaluando modelo: deepseek/deepseek-chat-v3.1\n",
            "  ⚠ 324 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7118\n",
            "  • Recall:    0.7160\n",
            "  • F1 Score:  0.7135\n",
            "    - Procesados: 4573\n",
            "    - Errores/omitidos: 324\n",
            "Evaluando modelo: moonshotai/kimi-k2-0905\n",
            "  ⚠ 638 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.6584\n",
            "  • Recall:    0.6560\n",
            "  • F1 Score:  0.6568\n",
            "    - Procesados: 4259\n",
            "    - Errores/omitidos: 638\n",
            "Evaluando modelo: openai/o4-mini-high\n",
            "  ⚠ 160 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7313\n",
            "  • Recall:    0.7245\n",
            "  • F1 Score:  0.7275\n",
            "    - Procesados: 4737\n",
            "    - Errores/omitidos: 160\n",
            "Evaluando modelo: openai/gpt-4.1\n",
            "  ⚠ 18 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7603\n",
            "  • Recall:    0.7510\n",
            "  • F1 Score:  0.7552\n",
            "    - Procesados: 4879\n",
            "    - Errores/omitidos: 18\n",
            "Evaluando modelo: openai/o1-mini\n",
            "  ⚠ 6 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7558\n",
            "  • Recall:    0.7483\n",
            "  • F1 Score:  0.7516\n",
            "    - Procesados: 4891\n",
            "    - Errores/omitidos: 6\n",
            "Evaluando modelo: anthropic/claude-sonnet-4\n",
            "  ⚠ 149 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7361\n",
            "  • Recall:    0.7455\n",
            "  • F1 Score:  0.7403\n",
            "    - Procesados: 4748\n",
            "    - Errores/omitidos: 149\n",
            "Evaluando modelo: gpt-5.1\n",
            "  ⚠ 4 registros omitidos se cuentan con score 0\n",
            "  • Precision: 0.7666\n",
            "  • Recall:    0.7674\n",
            "  • F1 Score:  0.7665\n",
            "    - Procesados: 4893\n",
            "    - Errores/omitidos: 4\n",
            "\n",
            "RESULTADOS con SciBETO:\n",
            "   amazon/nova-micro-v1:\n",
            "      • Precision: 0.7277\n",
            "      • Recall:    0.7183\n",
            "      • F1 Score:  0.7226 (±0.0868) [4897/4897]\n",
            "   microsoft/phi-4:\n",
            "      • Precision: 0.7301\n",
            "      • Recall:    0.7386\n",
            "      • F1 Score:  0.7340 (±0.0841) [4897/4897]\n",
            "   amazon/nova-lite-v1:\n",
            "      • Precision: 0.7633\n",
            "      • Recall:    0.7549\n",
            "      • F1 Score:  0.7586 (±0.0642) [4897/4897]\n",
            "   cohere/command-r-08-2024:\n",
            "      • Precision: 0.7580\n",
            "      • Recall:    0.7534\n",
            "      • F1 Score:  0.7553 (±0.0940) [4897/4897]\n",
            "   qwen/qwen-2.5-72b-instruct:\n",
            "      • Precision: 0.6765\n",
            "      • Recall:    0.6608\n",
            "      • F1 Score:  0.6681 (±0.2463) [4897/4897]\n",
            "   google/gemma-2-27b-it:\n",
            "      • Precision: 0.7455\n",
            "      • Recall:    0.7285\n",
            "      • F1 Score:  0.7364 (±0.1079) [4897/4897]\n",
            "   meta-llama/llama-3.3-70b-instruct:\n",
            "      • Precision: 0.7282\n",
            "      • Recall:    0.7119\n",
            "      • F1 Score:  0.7195 (±0.1224) [4897/4897]\n",
            "   microsoft/wizardlm-2-8x22b:\n",
            "      • Precision: 0.0000\n",
            "      • Recall:    0.0000\n",
            "      • F1 Score:  0.0000 (±0.0000) [4897/4897]\n",
            "   meta-llama/llama-4-maverick:\n",
            "      • Precision: 0.7538\n",
            "      • Recall:    0.7442\n",
            "      • F1 Score:  0.7485 (±0.0729) [4897/4897]\n",
            "   qwen/qwen2.5-vl-32b-instruct:free:\n",
            "      • Precision: 0.0000\n",
            "      • Recall:    0.0000\n",
            "      • F1 Score:  0.0000 (±0.0000) [4897/4897]\n",
            "   x-ai/grok-3-mini-beta:\n",
            "      • Precision: 0.7110\n",
            "      • Recall:    0.7043\n",
            "      • F1 Score:  0.7072 (±0.1820) [4897/4897]\n",
            "   perplexity/sonar:\n",
            "      • Precision: 0.7713\n",
            "      • Recall:    0.7673\n",
            "      • F1 Score:  0.7688 (±0.0517) [4897/4897]\n",
            "   mistralai/mistral-medium-3:\n",
            "      • Precision: 0.7598\n",
            "      • Recall:    0.7468\n",
            "      • F1 Score:  0.7528 (±0.1419) [4897/4897]\n",
            "   mistralai/mixtral-8x7b-instruct:\n",
            "      • Precision: 0.6734\n",
            "      • Recall:    0.6811\n",
            "      • F1 Score:  0.6769 (±0.2041) [4897/4897]\n",
            "   google/gemini-2.5-flash:\n",
            "      • Precision: 0.7406\n",
            "      • Recall:    0.7221\n",
            "      • F1 Score:  0.7307 (±0.1898) [4897/4897]\n",
            "   meta-llama/llama-3.1-405b-instruct:\n",
            "      • Precision: 0.6883\n",
            "      • Recall:    0.6860\n",
            "      • F1 Score:  0.6867 (±0.2210) [4897/4897]\n",
            "   deepseek/deepseek-chat-v3.1:\n",
            "      • Precision: 0.7118\n",
            "      • Recall:    0.7160\n",
            "      • F1 Score:  0.7135 (±0.1946) [4897/4897]\n",
            "   moonshotai/kimi-k2-0905:\n",
            "      • Precision: 0.6584\n",
            "      • Recall:    0.6560\n",
            "      • F1 Score:  0.6568 (±0.2574) [4897/4897]\n",
            "   openai/o4-mini-high:\n",
            "      • Precision: 0.7313\n",
            "      • Recall:    0.7245\n",
            "      • F1 Score:  0.7275 (±0.1405) [4897/4897]\n",
            "   openai/gpt-4.1:\n",
            "      • Precision: 0.7603\n",
            "      • Recall:    0.7510\n",
            "      • F1 Score:  0.7552 (±0.0639) [4897/4897]\n",
            "   openai/o1-mini:\n",
            "      • Precision: 0.7558\n",
            "      • Recall:    0.7483\n",
            "      • F1 Score:  0.7516 (±0.0515) [4897/4897]\n",
            "   anthropic/claude-sonnet-4:\n",
            "      • Precision: 0.7361\n",
            "      • Recall:    0.7455\n",
            "      • F1 Score:  0.7403 (±0.1380) [4897/4897]\n",
            "   gpt-5.1:\n",
            "      • Precision: 0.7666\n",
            "      • Recall:    0.7674\n",
            "      • F1 Score:  0.7665 (±0.0478) [4897/4897]\n",
            "\n",
            "✓ Guardado en: /content/drive/MyDrive/LLMs_Metrics/Metrics_Results/prompt_3_scibeto_bertscore_resultados.json\n",
            "\n",
            "============================================================\n",
            "Calculando Sentence-BERT Similarity con SciBETO-mean\n",
            "============================================================\n",
            "Evaluando modelo: amazon/nova-micro-v1\n",
            "  ⚠ 55 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5782\n",
            "    - Procesados: 4842\n",
            "    - Errores/omitidos: 55\n",
            "Evaluando modelo: microsoft/phi-4\n",
            "  ⚠ 51 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6818\n",
            "    - Procesados: 4846\n",
            "    - Errores/omitidos: 51\n",
            "Evaluando modelo: amazon/nova-lite-v1\n",
            "  ⚠ 21 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6885\n",
            "    - Procesados: 4876\n",
            "    - Errores/omitidos: 21\n",
            "Evaluando modelo: cohere/command-r-08-2024\n",
            "  ⚠ 62 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.7031\n",
            "    - Procesados: 4835\n",
            "    - Errores/omitidos: 62\n",
            "Evaluando modelo: qwen/qwen-2.5-72b-instruct\n",
            "  ⚠ 570 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5738\n",
            "    - Procesados: 4327\n",
            "    - Errores/omitidos: 570\n",
            "Evaluando modelo: google/gemma-2-27b-it\n",
            "  ⚠ 86 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6209\n",
            "    - Procesados: 4811\n",
            "    - Errores/omitidos: 86\n",
            "Evaluando modelo: meta-llama/llama-3.3-70b-instruct\n",
            "  ⚠ 120 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5734\n",
            "    - Procesados: 4777\n",
            "    - Errores/omitidos: 120\n",
            "Evaluando modelo: microsoft/wizardlm-2-8x22b\n",
            "  ⚠ No hay datos para microsoft/wizardlm-2-8x22b - todos los registros con similarity 0\n",
            "  • Similitud: 0.0000 (0/4897)\n",
            "Evaluando modelo: meta-llama/llama-4-maverick\n",
            "  ⚠ 28 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6424\n",
            "    - Procesados: 4869\n",
            "    - Errores/omitidos: 28\n",
            "Evaluando modelo: qwen/qwen2.5-vl-32b-instruct:free\n",
            "  ⚠ No hay datos para qwen/qwen2.5-vl-32b-instruct:free - todos los registros con similarity 0\n",
            "  • Similitud: 0.0000 (0/4897)\n",
            "Evaluando modelo: x-ai/grok-3-mini-beta\n",
            "  ⚠ 291 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6172\n",
            "    - Procesados: 4606\n",
            "    - Errores/omitidos: 291\n",
            "Evaluando modelo: perplexity/sonar\n",
            "  ⚠ 3 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.7066\n",
            "    - Procesados: 4894\n",
            "    - Errores/omitidos: 3\n",
            "Evaluando modelo: mistralai/mistral-medium-3\n",
            "  ⚠ 154 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6942\n",
            "    - Procesados: 4743\n",
            "    - Errores/omitidos: 154\n",
            "Evaluando modelo: mistralai/mixtral-8x7b-instruct\n",
            "  ⚠ 396 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6205\n",
            "    - Procesados: 4501\n",
            "    - Errores/omitidos: 396\n",
            "Evaluando modelo: google/gemini-2.5-flash\n",
            "  ⚠ 295 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6633\n",
            "    - Procesados: 4602\n",
            "    - Errores/omitidos: 295\n",
            "Evaluando modelo: meta-llama/llama-3.1-405b-instruct\n",
            "  ⚠ 445 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6142\n",
            "    - Procesados: 4452\n",
            "    - Errores/omitidos: 445\n",
            "Evaluando modelo: deepseek/deepseek-chat-v3.1\n",
            "  ⚠ 324 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6651\n",
            "    - Procesados: 4573\n",
            "    - Errores/omitidos: 324\n",
            "Evaluando modelo: moonshotai/kimi-k2-0905\n",
            "  ⚠ 638 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5896\n",
            "    - Procesados: 4259\n",
            "    - Errores/omitidos: 638\n",
            "Evaluando modelo: openai/o4-mini-high\n",
            "  ⚠ 160 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6355\n",
            "    - Procesados: 4737\n",
            "    - Errores/omitidos: 160\n",
            "Evaluando modelo: openai/gpt-4.1\n",
            "  ⚠ 18 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6662\n",
            "    - Procesados: 4879\n",
            "    - Errores/omitidos: 18\n",
            "Evaluando modelo: openai/o1-mini\n",
            "  ⚠ 6 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6556\n",
            "    - Procesados: 4891\n",
            "    - Errores/omitidos: 6\n",
            "Evaluando modelo: anthropic/claude-sonnet-4\n",
            "  ⚠ 149 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.7022\n",
            "    - Procesados: 4748\n",
            "    - Errores/omitidos: 149\n",
            "Evaluando modelo: gpt-5.1\n",
            "  ⚠ 4 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.7148\n",
            "    - Procesados: 4893\n",
            "    - Errores/omitidos: 4\n",
            "\n",
            "RESULTADOS con Sentence-BERT (SciBETO-mean):\n",
            "   amazon/nova-micro-v1:\n",
            "      • Similitud: 0.5782 (±0.1552) [4897/4897]\n",
            "   microsoft/phi-4:\n",
            "      • Similitud: 0.6818 (±0.1518) [4897/4897]\n",
            "   amazon/nova-lite-v1:\n",
            "      • Similitud: 0.6885 (±0.1298) [4897/4897]\n",
            "   cohere/command-r-08-2024:\n",
            "      • Similitud: 0.7031 (±0.1438) [4897/4897]\n",
            "   qwen/qwen-2.5-72b-instruct:\n",
            "      • Similitud: 0.5738 (±0.2363) [4897/4897]\n",
            "   google/gemma-2-27b-it:\n",
            "      • Similitud: 0.6209 (±0.1525) [4897/4897]\n",
            "   meta-llama/llama-3.3-70b-instruct:\n",
            "      • Similitud: 0.5734 (±0.1515) [4897/4897]\n",
            "   microsoft/wizardlm-2-8x22b:\n",
            "      • Similitud: 0.0000 (±0.0000) [4897/4897]\n",
            "   meta-llama/llama-4-maverick:\n",
            "      • Similitud: 0.6424 (±0.1210) [4897/4897]\n",
            "   qwen/qwen2.5-vl-32b-instruct:free:\n",
            "      • Similitud: 0.0000 (±0.0000) [4897/4897]\n",
            "   x-ai/grok-3-mini-beta:\n",
            "      • Similitud: 0.6172 (±0.1893) [4897/4897]\n",
            "   perplexity/sonar:\n",
            "      • Similitud: 0.7066 (±0.1276) [4897/4897]\n",
            "   mistralai/mistral-medium-3:\n",
            "      • Similitud: 0.6942 (±0.1714) [4897/4897]\n",
            "   mistralai/mixtral-8x7b-instruct:\n",
            "      • Similitud: 0.6205 (±0.2223) [4897/4897]\n",
            "   google/gemini-2.5-flash:\n",
            "      • Similitud: 0.6633 (±0.2035) [4897/4897]\n",
            "   meta-llama/llama-3.1-405b-instruct:\n",
            "      • Similitud: 0.6142 (±0.2277) [4897/4897]\n",
            "   deepseek/deepseek-chat-v3.1:\n",
            "      • Similitud: 0.6651 (±0.2154) [4897/4897]\n",
            "   moonshotai/kimi-k2-0905:\n",
            "      • Similitud: 0.5896 (±0.2555) [4897/4897]\n",
            "   openai/o4-mini-high:\n",
            "      • Similitud: 0.6355 (±0.1673) [4897/4897]\n",
            "   openai/gpt-4.1:\n",
            "      • Similitud: 0.6662 (±0.1198) [4897/4897]\n",
            "   openai/o1-mini:\n",
            "      • Similitud: 0.6556 (±0.1227) [4897/4897]\n",
            "   anthropic/claude-sonnet-4:\n",
            "      • Similitud: 0.7022 (±0.1778) [4897/4897]\n",
            "   gpt-5.1:\n",
            "      • Similitud: 0.7148 (±0.1201) [4897/4897]\n",
            "\n",
            "✓ Guardado en: /content/drive/MyDrive/LLMs_Metrics/Metrics_Results/prompt_3_scibeto-mean_sbert_similarity_resultados.json\n",
            "\n",
            "============================================================\n",
            "Calculando Sentence-BERT Similarity con paraphrase-mpnet\n",
            "============================================================\n",
            "Evaluando modelo: amazon/nova-micro-v1\n",
            "  ⚠ 55 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5086\n",
            "    - Procesados: 4842\n",
            "    - Errores/omitidos: 55\n",
            "Evaluando modelo: microsoft/phi-4\n",
            "  ⚠ 51 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.4687\n",
            "    - Procesados: 4846\n",
            "    - Errores/omitidos: 51\n",
            "Evaluando modelo: amazon/nova-lite-v1\n",
            "  ⚠ 21 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5389\n",
            "    - Procesados: 4876\n",
            "    - Errores/omitidos: 21\n",
            "Evaluando modelo: cohere/command-r-08-2024\n",
            "  ⚠ 62 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5433\n",
            "    - Procesados: 4835\n",
            "    - Errores/omitidos: 62\n",
            "Evaluando modelo: qwen/qwen-2.5-72b-instruct\n",
            "  ⚠ 570 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5013\n",
            "    - Procesados: 4327\n",
            "    - Errores/omitidos: 570\n",
            "Evaluando modelo: google/gemma-2-27b-it\n",
            "  ⚠ 86 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5209\n",
            "    - Procesados: 4811\n",
            "    - Errores/omitidos: 86\n",
            "Evaluando modelo: meta-llama/llama-3.3-70b-instruct\n",
            "  ⚠ 120 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5271\n",
            "    - Procesados: 4777\n",
            "    - Errores/omitidos: 120\n",
            "Evaluando modelo: microsoft/wizardlm-2-8x22b\n",
            "  ⚠ No hay datos para microsoft/wizardlm-2-8x22b - todos los registros con similarity 0\n",
            "  • Similitud: 0.0000 (0/4897)\n",
            "Evaluando modelo: meta-llama/llama-4-maverick\n",
            "  ⚠ 28 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5882\n",
            "    - Procesados: 4869\n",
            "    - Errores/omitidos: 28\n",
            "Evaluando modelo: qwen/qwen2.5-vl-32b-instruct:free\n",
            "  ⚠ No hay datos para qwen/qwen2.5-vl-32b-instruct:free - todos los registros con similarity 0\n",
            "  • Similitud: 0.0000 (0/4897)\n",
            "Evaluando modelo: x-ai/grok-3-mini-beta\n",
            "  ⚠ 291 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5586\n",
            "    - Procesados: 4606\n",
            "    - Errores/omitidos: 291\n",
            "Evaluando modelo: perplexity/sonar\n",
            "  ⚠ 3 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6513\n",
            "    - Procesados: 4894\n",
            "    - Errores/omitidos: 3\n",
            "Evaluando modelo: mistralai/mistral-medium-3\n",
            "  ⚠ 154 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5859\n",
            "    - Procesados: 4743\n",
            "    - Errores/omitidos: 154\n",
            "Evaluando modelo: mistralai/mixtral-8x7b-instruct\n",
            "  ⚠ 396 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.4982\n",
            "    - Procesados: 4501\n",
            "    - Errores/omitidos: 396\n",
            "Evaluando modelo: google/gemini-2.5-flash\n",
            "  ⚠ 295 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5814\n",
            "    - Procesados: 4602\n",
            "    - Errores/omitidos: 295\n",
            "Evaluando modelo: meta-llama/llama-3.1-405b-instruct\n",
            "  ⚠ 445 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5204\n",
            "    - Procesados: 4452\n",
            "    - Errores/omitidos: 445\n",
            "Evaluando modelo: deepseek/deepseek-chat-v3.1\n",
            "  ⚠ 324 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5718\n",
            "    - Procesados: 4573\n",
            "    - Errores/omitidos: 324\n",
            "Evaluando modelo: moonshotai/kimi-k2-0905\n",
            "  ⚠ 638 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5297\n",
            "    - Procesados: 4259\n",
            "    - Errores/omitidos: 638\n",
            "Evaluando modelo: openai/o4-mini-high\n",
            "  ⚠ 160 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5833\n",
            "    - Procesados: 4737\n",
            "    - Errores/omitidos: 160\n",
            "Evaluando modelo: openai/gpt-4.1\n",
            "  ⚠ 18 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6369\n",
            "    - Procesados: 4879\n",
            "    - Errores/omitidos: 18\n",
            "Evaluando modelo: openai/o1-mini\n",
            "  ⚠ 6 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6046\n",
            "    - Procesados: 4891\n",
            "    - Errores/omitidos: 6\n",
            "Evaluando modelo: anthropic/claude-sonnet-4\n",
            "  ⚠ 149 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6207\n",
            "    - Procesados: 4748\n",
            "    - Errores/omitidos: 149\n",
            "Evaluando modelo: gpt-5.1\n",
            "  ⚠ 4 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6459\n",
            "    - Procesados: 4893\n",
            "    - Errores/omitidos: 4\n",
            "\n",
            "RESULTADOS con Sentence-BERT (paraphrase-mpnet):\n",
            "   amazon/nova-micro-v1:\n",
            "      • Similitud: 0.5086 (±0.2006) [4897/4897]\n",
            "   microsoft/phi-4:\n",
            "      • Similitud: 0.4687 (±0.2109) [4897/4897]\n",
            "   amazon/nova-lite-v1:\n",
            "      • Similitud: 0.5389 (±0.2007) [4897/4897]\n",
            "   cohere/command-r-08-2024:\n",
            "      • Similitud: 0.5433 (±0.2078) [4897/4897]\n",
            "   qwen/qwen-2.5-72b-instruct:\n",
            "      • Similitud: 0.5013 (±0.2597) [4897/4897]\n",
            "   google/gemma-2-27b-it:\n",
            "      • Similitud: 0.5209 (±0.2073) [4897/4897]\n",
            "   meta-llama/llama-3.3-70b-instruct:\n",
            "      • Similitud: 0.5271 (±0.2088) [4897/4897]\n",
            "   microsoft/wizardlm-2-8x22b:\n",
            "      • Similitud: 0.0000 (±0.0000) [4897/4897]\n",
            "   meta-llama/llama-4-maverick:\n",
            "      • Similitud: 0.5882 (±0.2015) [4897/4897]\n",
            "   qwen/qwen2.5-vl-32b-instruct:free:\n",
            "      • Similitud: 0.0000 (±0.0000) [4897/4897]\n",
            "   x-ai/grok-3-mini-beta:\n",
            "      • Similitud: 0.5586 (±0.2345) [4897/4897]\n",
            "   perplexity/sonar:\n",
            "      • Similitud: 0.6513 (±0.1880) [4897/4897]\n",
            "   mistralai/mistral-medium-3:\n",
            "      • Similitud: 0.5859 (±0.2152) [4897/4897]\n",
            "   mistralai/mixtral-8x7b-instruct:\n",
            "      • Similitud: 0.4982 (±0.2414) [4897/4897]\n",
            "   google/gemini-2.5-flash:\n",
            "      • Similitud: 0.5814 (±0.2322) [4897/4897]\n",
            "   meta-llama/llama-3.1-405b-instruct:\n",
            "      • Similitud: 0.5204 (±0.2498) [4897/4897]\n",
            "   deepseek/deepseek-chat-v3.1:\n",
            "      • Similitud: 0.5718 (±0.2453) [4897/4897]\n",
            "   moonshotai/kimi-k2-0905:\n",
            "      • Similitud: 0.5297 (±0.2684) [4897/4897]\n",
            "   openai/o4-mini-high:\n",
            "      • Similitud: 0.5833 (±0.2223) [4897/4897]\n",
            "   openai/gpt-4.1:\n",
            "      • Similitud: 0.6369 (±0.1839) [4897/4897]\n",
            "   openai/o1-mini:\n",
            "      • Similitud: 0.6046 (±0.1963) [4897/4897]\n",
            "   anthropic/claude-sonnet-4:\n",
            "      • Similitud: 0.6207 (±0.2137) [4897/4897]\n",
            "   gpt-5.1:\n",
            "      • Similitud: 0.6459 (±0.1800) [4897/4897]\n",
            "\n",
            "✓ Guardado en: /content/drive/MyDrive/LLMs_Metrics/Metrics_Results/prompt_3_paraphrase-mpnet_sbert_similarity_resultados.json\n",
            "\n",
            "============================================================\n",
            "Calculando Sentence-BERT Similarity con XLM-RoBERTa\n",
            "============================================================\n",
            "Evaluando modelo: amazon/nova-micro-v1\n",
            "  ⚠ 55 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.4736\n",
            "    - Procesados: 4842\n",
            "    - Errores/omitidos: 55\n",
            "Evaluando modelo: microsoft/phi-4\n",
            "  ⚠ 51 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.4314\n",
            "    - Procesados: 4846\n",
            "    - Errores/omitidos: 51\n",
            "Evaluando modelo: amazon/nova-lite-v1\n",
            "  ⚠ 21 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.4940\n",
            "    - Procesados: 4876\n",
            "    - Errores/omitidos: 21\n",
            "Evaluando modelo: cohere/command-r-08-2024\n",
            "  ⚠ 62 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5034\n",
            "    - Procesados: 4835\n",
            "    - Errores/omitidos: 62\n",
            "Evaluando modelo: qwen/qwen-2.5-72b-instruct\n",
            "  ⚠ 570 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.4677\n",
            "    - Procesados: 4327\n",
            "    - Errores/omitidos: 570\n",
            "Evaluando modelo: google/gemma-2-27b-it\n",
            "  ⚠ 86 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.4800\n",
            "    - Procesados: 4811\n",
            "    - Errores/omitidos: 86\n",
            "Evaluando modelo: meta-llama/llama-3.3-70b-instruct\n",
            "  ⚠ 120 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.4951\n",
            "    - Procesados: 4777\n",
            "    - Errores/omitidos: 120\n",
            "Evaluando modelo: microsoft/wizardlm-2-8x22b\n",
            "  ⚠ No hay datos para microsoft/wizardlm-2-8x22b - todos los registros con similarity 0\n",
            "  • Similitud: 0.0000 (0/4897)\n",
            "Evaluando modelo: meta-llama/llama-4-maverick\n",
            "  ⚠ 28 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5525\n",
            "    - Procesados: 4869\n",
            "    - Errores/omitidos: 28\n",
            "Evaluando modelo: qwen/qwen2.5-vl-32b-instruct:free\n",
            "  ⚠ No hay datos para qwen/qwen2.5-vl-32b-instruct:free - todos los registros con similarity 0\n",
            "  • Similitud: 0.0000 (0/4897)\n",
            "Evaluando modelo: x-ai/grok-3-mini-beta\n",
            "  ⚠ 291 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5322\n",
            "    - Procesados: 4606\n",
            "    - Errores/omitidos: 291\n",
            "Evaluando modelo: perplexity/sonar\n",
            "  ⚠ 3 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6175\n",
            "    - Procesados: 4894\n",
            "    - Errores/omitidos: 3\n",
            "Evaluando modelo: mistralai/mistral-medium-3\n",
            "  ⚠ 154 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5409\n",
            "    - Procesados: 4743\n",
            "    - Errores/omitidos: 154\n",
            "Evaluando modelo: mistralai/mixtral-8x7b-instruct\n",
            "  ⚠ 396 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.4640\n",
            "    - Procesados: 4501\n",
            "    - Errores/omitidos: 396\n",
            "Evaluando modelo: google/gemini-2.5-flash\n",
            "  ⚠ 295 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5429\n",
            "    - Procesados: 4602\n",
            "    - Errores/omitidos: 295\n",
            "Evaluando modelo: meta-llama/llama-3.1-405b-instruct\n",
            "  ⚠ 445 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.4851\n",
            "    - Procesados: 4452\n",
            "    - Errores/omitidos: 445\n",
            "Evaluando modelo: deepseek/deepseek-chat-v3.1\n",
            "  ⚠ 324 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5426\n",
            "    - Procesados: 4573\n",
            "    - Errores/omitidos: 324\n",
            "Evaluando modelo: moonshotai/kimi-k2-0905\n",
            "  ⚠ 638 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.4971\n",
            "    - Procesados: 4259\n",
            "    - Errores/omitidos: 638\n",
            "Evaluando modelo: openai/o4-mini-high\n",
            "  ⚠ 160 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5521\n",
            "    - Procesados: 4737\n",
            "    - Errores/omitidos: 160\n",
            "Evaluando modelo: openai/gpt-4.1\n",
            "  ⚠ 18 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5992\n",
            "    - Procesados: 4879\n",
            "    - Errores/omitidos: 18\n",
            "Evaluando modelo: openai/o1-mini\n",
            "  ⚠ 6 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5745\n",
            "    - Procesados: 4891\n",
            "    - Errores/omitidos: 6\n",
            "Evaluando modelo: anthropic/claude-sonnet-4\n",
            "  ⚠ 149 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.5915\n",
            "    - Procesados: 4748\n",
            "    - Errores/omitidos: 149\n",
            "Evaluando modelo: gpt-5.1\n",
            "  ⚠ 4 registros omitidos se cuentan con similarity 0\n",
            "  • Similitud: 0.6036\n",
            "    - Procesados: 4893\n",
            "    - Errores/omitidos: 4\n",
            "\n",
            "RESULTADOS con Sentence-BERT (XLM-RoBERTa):\n",
            "   amazon/nova-micro-v1:\n",
            "      • Similitud: 0.4736 (±0.2192) [4897/4897]\n",
            "   microsoft/phi-4:\n",
            "      • Similitud: 0.4314 (±0.2235) [4897/4897]\n",
            "   amazon/nova-lite-v1:\n",
            "      • Similitud: 0.4940 (±0.2194) [4897/4897]\n",
            "   cohere/command-r-08-2024:\n",
            "      • Similitud: 0.5034 (±0.2248) [4897/4897]\n",
            "   qwen/qwen-2.5-72b-instruct:\n",
            "      • Similitud: 0.4677 (±0.2680) [4897/4897]\n",
            "   google/gemma-2-27b-it:\n",
            "      • Similitud: 0.4800 (±0.2291) [4897/4897]\n",
            "   meta-llama/llama-3.3-70b-instruct:\n",
            "      • Similitud: 0.4951 (±0.2279) [4897/4897]\n",
            "   microsoft/wizardlm-2-8x22b:\n",
            "      • Similitud: 0.0000 (±0.0000) [4897/4897]\n",
            "   meta-llama/llama-4-maverick:\n",
            "      • Similitud: 0.5525 (±0.2247) [4897/4897]\n",
            "   qwen/qwen2.5-vl-32b-instruct:free:\n",
            "      • Similitud: 0.0000 (±0.0000) [4897/4897]\n",
            "   x-ai/grok-3-mini-beta:\n",
            "      • Similitud: 0.5322 (±0.2443) [4897/4897]\n",
            "   perplexity/sonar:\n",
            "      • Similitud: 0.6175 (±0.2084) [4897/4897]\n",
            "   mistralai/mistral-medium-3:\n",
            "      • Similitud: 0.5409 (±0.2302) [4897/4897]\n",
            "   mistralai/mixtral-8x7b-instruct:\n",
            "      • Similitud: 0.4640 (±0.2483) [4897/4897]\n",
            "   google/gemini-2.5-flash:\n",
            "      • Similitud: 0.5429 (±0.2450) [4897/4897]\n",
            "   meta-llama/llama-3.1-405b-instruct:\n",
            "      • Similitud: 0.4851 (±0.2580) [4897/4897]\n",
            "   deepseek/deepseek-chat-v3.1:\n",
            "      • Similitud: 0.5426 (±0.2548) [4897/4897]\n",
            "   moonshotai/kimi-k2-0905:\n",
            "      • Similitud: 0.4971 (±0.2744) [4897/4897]\n",
            "   openai/o4-mini-high:\n",
            "      • Similitud: 0.5521 (±0.2349) [4897/4897]\n",
            "   openai/gpt-4.1:\n",
            "      • Similitud: 0.5992 (±0.2063) [4897/4897]\n",
            "   openai/o1-mini:\n",
            "      • Similitud: 0.5745 (±0.2164) [4897/4897]\n",
            "   anthropic/claude-sonnet-4:\n",
            "      • Similitud: 0.5915 (±0.2286) [4897/4897]\n",
            "   gpt-5.1:\n",
            "      • Similitud: 0.6036 (±0.2002) [4897/4897]\n",
            "\n",
            "✓ Guardado en: /content/drive/MyDrive/LLMs_Metrics/Metrics_Results/prompt_3_xlm-roberta_sbert_similarity_resultados.json\n",
            "\n",
            "============================================================\n",
            "Calculando chrF Score\n",
            "============================================================\n",
            "Evaluando modelo: amazon/nova-micro-v1\n",
            "  ⚠ 55 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.1835\n",
            "    - Procesados: 4842\n",
            "    - Errores/omitidos: 55\n",
            "Evaluando modelo: microsoft/phi-4\n",
            "  ⚠ 51 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2354\n",
            "    - Procesados: 4846\n",
            "    - Errores/omitidos: 51\n",
            "Evaluando modelo: amazon/nova-lite-v1\n",
            "  ⚠ 21 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2401\n",
            "    - Procesados: 4876\n",
            "    - Errores/omitidos: 21\n",
            "Evaluando modelo: cohere/command-r-08-2024\n",
            "  ⚠ 62 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2501\n",
            "    - Procesados: 4835\n",
            "    - Errores/omitidos: 62\n",
            "Evaluando modelo: qwen/qwen-2.5-72b-instruct\n",
            "  ⚠ 570 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.1951\n",
            "    - Procesados: 4327\n",
            "    - Errores/omitidos: 570\n",
            "Evaluando modelo: google/gemma-2-27b-it\n",
            "  ⚠ 86 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2014\n",
            "    - Procesados: 4811\n",
            "    - Errores/omitidos: 86\n",
            "Evaluando modelo: meta-llama/llama-3.3-70b-instruct\n",
            "  ⚠ 120 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.1872\n",
            "    - Procesados: 4777\n",
            "    - Errores/omitidos: 120\n",
            "Evaluando modelo: microsoft/wizardlm-2-8x22b\n",
            "  ⚠ No hay datos para microsoft/wizardlm-2-8x22b - todos los registros con chrF 0\n",
            "  • chrF: 0.0000 (0/4897)\n",
            "Evaluando modelo: meta-llama/llama-4-maverick\n",
            "  ⚠ 28 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2401\n",
            "    - Procesados: 4869\n",
            "    - Errores/omitidos: 28\n",
            "Evaluando modelo: qwen/qwen2.5-vl-32b-instruct:free\n",
            "  ⚠ No hay datos para qwen/qwen2.5-vl-32b-instruct:free - todos los registros con chrF 0\n",
            "  • chrF: 0.0000 (0/4897)\n",
            "Evaluando modelo: x-ai/grok-3-mini-beta\n",
            "  ⚠ 291 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2242\n",
            "    - Procesados: 4606\n",
            "    - Errores/omitidos: 291\n",
            "Evaluando modelo: perplexity/sonar\n",
            "  ⚠ 3 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2862\n",
            "    - Procesados: 4894\n",
            "    - Errores/omitidos: 3\n",
            "Evaluando modelo: mistralai/mistral-medium-3\n",
            "  ⚠ 154 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2534\n",
            "    - Procesados: 4743\n",
            "    - Errores/omitidos: 154\n",
            "Evaluando modelo: mistralai/mixtral-8x7b-instruct\n",
            "  ⚠ 396 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2289\n",
            "    - Procesados: 4501\n",
            "    - Errores/omitidos: 396\n",
            "Evaluando modelo: google/gemini-2.5-flash\n",
            "  ⚠ 295 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2371\n",
            "    - Procesados: 4602\n",
            "    - Errores/omitidos: 295\n",
            "Evaluando modelo: meta-llama/llama-3.1-405b-instruct\n",
            "  ⚠ 445 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2266\n",
            "    - Procesados: 4452\n",
            "    - Errores/omitidos: 445\n",
            "Evaluando modelo: deepseek/deepseek-chat-v3.1\n",
            "  ⚠ 324 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2637\n",
            "    - Procesados: 4573\n",
            "    - Errores/omitidos: 324\n",
            "Evaluando modelo: moonshotai/kimi-k2-0905\n",
            "  ⚠ 638 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2162\n",
            "    - Procesados: 4259\n",
            "    - Errores/omitidos: 638\n",
            "Evaluando modelo: openai/o4-mini-high\n",
            "  ⚠ 160 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2343\n",
            "    - Procesados: 4737\n",
            "    - Errores/omitidos: 160\n",
            "Evaluando modelo: openai/gpt-4.1\n",
            "  ⚠ 18 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2562\n",
            "    - Procesados: 4879\n",
            "    - Errores/omitidos: 18\n",
            "Evaluando modelo: openai/o1-mini\n",
            "  ⚠ 6 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2426\n",
            "    - Procesados: 4891\n",
            "    - Errores/omitidos: 6\n",
            "Evaluando modelo: anthropic/claude-sonnet-4\n",
            "  ⚠ 149 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2897\n",
            "    - Procesados: 4748\n",
            "    - Errores/omitidos: 149\n",
            "Evaluando modelo: gpt-5.1\n",
            "  ⚠ 4 registros omitidos se cuentan con chrF 0\n",
            "  • chrF: 0.2775\n",
            "    - Procesados: 4893\n",
            "    - Errores/omitidos: 4\n",
            "\n",
            "RESULTADOS con chrF:\n",
            "   amazon/nova-micro-v1:\n",
            "      • chrF: 0.1835 (±0.0858) [4897/4897]\n",
            "   microsoft/phi-4:\n",
            "      • chrF: 0.2354 (±0.0912) [4897/4897]\n",
            "   amazon/nova-lite-v1:\n",
            "      • chrF: 0.2401 (±0.0973) [4897/4897]\n",
            "   cohere/command-r-08-2024:\n",
            "      • chrF: 0.2501 (±0.1034) [4897/4897]\n",
            "   qwen/qwen-2.5-72b-instruct:\n",
            "      • chrF: 0.1951 (±0.1208) [4897/4897]\n",
            "   google/gemma-2-27b-it:\n",
            "      • chrF: 0.2014 (±0.1002) [4897/4897]\n",
            "   meta-llama/llama-3.3-70b-instruct:\n",
            "      • chrF: 0.1872 (±0.1065) [4897/4897]\n",
            "   microsoft/wizardlm-2-8x22b:\n",
            "      • chrF: 0.0000 (±0.0000) [4897/4897]\n",
            "   meta-llama/llama-4-maverick:\n",
            "      • chrF: 0.2401 (±0.1153) [4897/4897]\n",
            "   qwen/qwen2.5-vl-32b-instruct:free:\n",
            "      • chrF: 0.0000 (±0.0000) [4897/4897]\n",
            "   x-ai/grok-3-mini-beta:\n",
            "      • chrF: 0.2242 (±0.1131) [4897/4897]\n",
            "   perplexity/sonar:\n",
            "      • chrF: 0.2862 (±0.1262) [4897/4897]\n",
            "   mistralai/mistral-medium-3:\n",
            "      • chrF: 0.2534 (±0.1170) [4897/4897]\n",
            "   mistralai/mixtral-8x7b-instruct:\n",
            "      • chrF: 0.2289 (±0.1165) [4897/4897]\n",
            "   google/gemini-2.5-flash:\n",
            "      • chrF: 0.2371 (±0.1256) [4897/4897]\n",
            "   meta-llama/llama-3.1-405b-instruct:\n",
            "      • chrF: 0.2266 (±0.1267) [4897/4897]\n",
            "   deepseek/deepseek-chat-v3.1:\n",
            "      • chrF: 0.2637 (±0.1322) [4897/4897]\n",
            "   moonshotai/kimi-k2-0905:\n",
            "      • chrF: 0.2162 (±0.1308) [4897/4897]\n",
            "   openai/o4-mini-high:\n",
            "      • chrF: 0.2343 (±0.1174) [4897/4897]\n",
            "   openai/gpt-4.1:\n",
            "      • chrF: 0.2562 (±0.1149) [4897/4897]\n",
            "   openai/o1-mini:\n",
            "      • chrF: 0.2426 (±0.1102) [4897/4897]\n",
            "   anthropic/claude-sonnet-4:\n",
            "      • chrF: 0.2897 (±0.1327) [4897/4897]\n",
            "   gpt-5.1:\n",
            "      • chrF: 0.2775 (±0.1080) [4897/4897]\n",
            "\n",
            "✓ Guardado en: /content/drive/MyDrive/LLMs_Metrics/Metrics_Results/prompt_3_chrf_resultados.json\n",
            "\n",
            "================================================================================\n",
            "PROMPT 3 COMPLETADO\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"PROMPT 3: Modismo + Ejemplo → Literal + Definición\")\n",
        "print(\"=\"*80)\n",
        "print(\"Objetivo: Evaluar si el modelo genera interpretaciones literales correctas\")\n",
        "print(\"Métricas:\")\n",
        "print(\"  - BERTScore (BETO y SciBETO): Similitud semántica con embeddings de BERT\")\n",
        "print(\"  - Sentence-BERT: Similitud con modelo multilingüe paraphrase-mpnet\")\n",
        "print(\"  - chrF: Character n-gram F-score\")\n",
        "print(\"Nota: Los errores/omisiones se cuentan con score 0 en todas las métricas.\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Cargar datos desde JSON\n",
        "with open(os.path.join(DATA_DIR, 'prompt_3_metrics_data.json'), 'r', encoding='utf-8') as f:\n",
        "    data_p3 = json.load(f)\n",
        "\n",
        "# Filtrar datos con literal y definición generados\n",
        "data_p3_valid = [d for d in data_p3 if d.get('significado_real') and d.get('definicion_generada')]\n",
        "\n",
        "print(f\"Datos cargados: {len(data_p3_valid)} registros válidos de {len(data_p3)} totales\")\n",
        "print()\n",
        "\n",
        "# ============================================================================\n",
        "# 1. BERTScore con BETO y SciBETO\n",
        "# ============================================================================\n",
        "bert_models = [\n",
        "    ('BETO', compute_bertscore_beto),\n",
        "    ('SciBETO', compute_bertscore_sci_beto)\n",
        "\n",
        "]\n",
        "\n",
        "for bert_name, bert_func in bert_models:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Calculando BERTScore con {bert_name}\")\n",
        "    print('='*60)\n",
        "\n",
        "    resultados_p3 = []\n",
        "\n",
        "    for model in MODEL_NAMES:\n",
        "        print(f\"Evaluando modelo: {model}\")\n",
        "\n",
        "        # Filtrar datos de este modelo\n",
        "        model_data = [d for d in data_p3_valid if d.get('modelo') == model]\n",
        "\n",
        "        if not model_data:\n",
        "            print(f\"  ⚠ No hay datos para {model} - todos los registros con score 0\")\n",
        "            # Agregar todos los registros con score 0\n",
        "            for _ in range(GROUNTH_TRUTH):\n",
        "                resultados_p3.append({\n",
        "                    'modismo': 'N/A',\n",
        "                    'ejemplo': '',\n",
        "                    'modelo': model,\n",
        "                    'bert_model': bert_name,\n",
        "                    'precision': 0.0,\n",
        "                    'recall': 0.0,\n",
        "                    'f1_score': 0.0,\n",
        "                    'significado_real': '',\n",
        "                    'literal_generado': '',\n",
        "                    'definicion_generada': ''\n",
        "                })\n",
        "            print(f\"  • F1 Score: 0.0000 (0/{GROUNTH_TRUTH})\")\n",
        "            continue\n",
        "\n",
        "        referencias = [d['significado_real'] for d in model_data]\n",
        "        candidatos = [d['definicion_generada'] for d in model_data]\n",
        "\n",
        "        # BERTScore: compara definición generada vs significado real\n",
        "        P, R, F1 = bert_func(candidatos, referencias)\n",
        "\n",
        "        for idx, (p, r, f1) in enumerate(zip(P.tolist(), R.tolist(), F1.tolist())):\n",
        "            resultados_p3.append({\n",
        "                'modismo': model_data[idx]['modismo'],\n",
        "                'ejemplo': model_data[idx]['ejemplo'],\n",
        "                'modelo': model,\n",
        "                'bert_model': bert_name,\n",
        "                'precision': p,\n",
        "                'recall': r,\n",
        "                'f1_score': f1,\n",
        "                'significado_real': referencias[idx],\n",
        "                'literal_generado': model_data[idx].get('literal_generado', ''),\n",
        "                'definicion_generada': candidatos[idx]\n",
        "            })\n",
        "\n",
        "        # Calcular registros faltantes (omitidos por errores)\n",
        "        registros_procesados = len(model_data)\n",
        "        registros_faltantes = GROUNTH_TRUTH - registros_procesados\n",
        "\n",
        "        # Agregar registros faltantes con score 0\n",
        "        if registros_faltantes > 0:\n",
        "            print(f\"  ⚠ {registros_faltantes} registros omitidos se cuentan con score 0\")\n",
        "            for _ in range(registros_faltantes):\n",
        "                resultados_p3.append({\n",
        "                    'modismo': 'ERROR/OMITIDO',\n",
        "                    'ejemplo': '',\n",
        "                    'modelo': model,\n",
        "                    'bert_model': bert_name,\n",
        "                    'precision': 0.0,\n",
        "                    'recall': 0.0,\n",
        "                    'f1_score': 0.0,\n",
        "                    'significado_real': '',\n",
        "                    'literal_generado': '',\n",
        "                    'definicion_generada': ''\n",
        "                })\n",
        "\n",
        "        # Calcular promedios sobre el total (GROUNTH_TRUTH)\n",
        "        all_f1_scores = [r['f1_score'] for r in resultados_p3 if r['modelo'] == model and r['bert_model'] == bert_name]\n",
        "        all_precisions = [r['precision'] for r in resultados_p3 if r['modelo'] == model and r['bert_model'] == bert_name]\n",
        "        all_recalls = [r['recall'] for r in resultados_p3 if r['modelo'] == model and r['bert_model'] == bert_name]\n",
        "\n",
        "        f1_mean = np.mean(all_f1_scores)\n",
        "        p_mean = np.mean(all_precisions)\n",
        "        r_mean = np.mean(all_recalls)\n",
        "\n",
        "        print(f\"  • Precision: {p_mean:.4f}\")\n",
        "        print(f\"  • Recall:    {r_mean:.4f}\")\n",
        "        print(f\"  • F1 Score:  {f1_mean:.4f}\")\n",
        "        print(f\"    - Procesados: {registros_procesados}\")\n",
        "        print(f\"    - Errores/omitidos: {registros_faltantes}\")\n",
        "\n",
        "    # Guardar resultados\n",
        "    output_file = os.path.join(OUTPUT_DIR, f'prompt_3_{bert_name.lower()}_bertscore_resultados.json')\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(resultados_p3, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print()\n",
        "    print(f\"RESULTADOS con {bert_name}:\")\n",
        "    for model in MODEL_NAMES:\n",
        "        model_results = [r for r in resultados_p3 if r['modelo'] == model]\n",
        "        if model_results:\n",
        "            f1_scores = [r['f1_score'] for r in model_results]\n",
        "            precisions = [r['precision'] for r in model_results]\n",
        "            recalls = [r['recall'] for r in model_results]\n",
        "\n",
        "            f1_mean = np.mean(f1_scores)\n",
        "            f1_std = np.std(f1_scores)\n",
        "            p_mean = np.mean(precisions)\n",
        "            r_mean = np.mean(recalls)\n",
        "\n",
        "            print(f\"   {model}:\")\n",
        "            print(f\"      • Precision: {p_mean:.4f}\")\n",
        "            print(f\"      • Recall:    {r_mean:.4f}\")\n",
        "            print(f\"      • F1 Score:  {f1_mean:.4f} (±{f1_std:.4f}) [{len(model_results)}/{GROUNTH_TRUTH}]\")\n",
        "\n",
        "    print(f\"\\n✓ Guardado en: {output_file}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. Sentence-BERT Similarity\n",
        "# ============================================================================\n",
        "sbert_models = [\n",
        "    ('SciBETO-mean', compute_scibeto_similarity),\n",
        "    ('paraphrase-mpnet', compute_sbert_similarity),\n",
        "    ('XLM-RoBERTa', compute_xlm_similarity)\n",
        "\n",
        "]\n",
        "\n",
        "for sbert_name, sbert_func in sbert_models:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Calculando Sentence-BERT Similarity con {sbert_name}\")\n",
        "    print('='*60)\n",
        "\n",
        "    resultados_sbert = []\n",
        "\n",
        "    for model in MODEL_NAMES:\n",
        "        print(f\"Evaluando modelo: {model}\")\n",
        "\n",
        "        model_data = [d for d in data_p3_valid if d.get('modelo') == model]\n",
        "\n",
        "        if not model_data:\n",
        "            print(f\"  ⚠ No hay datos para {model} - todos los registros con similarity 0\")\n",
        "            # Agregar todos los registros con similarity 0\n",
        "            for _ in range(GROUNTH_TRUTH):\n",
        "                resultados_sbert.append({\n",
        "                    'modismo': 'N/A',\n",
        "                    'ejemplo': '',\n",
        "                    'modelo': model,\n",
        "                    'sbert_model': sbert_name,\n",
        "                    'similarity': 0.0,\n",
        "                    'significado_real': '',\n",
        "                    'literal_generado': '',\n",
        "                    'definicion_generada': ''\n",
        "                })\n",
        "            print(f\"  • Similitud: 0.0000 (0/{GROUNTH_TRUTH})\")\n",
        "            continue\n",
        "\n",
        "        referencias = [d['significado_real'] for d in model_data]\n",
        "        candidatos = [d['definicion_generada'] for d in model_data]\n",
        "\n",
        "        # Calcular similitud con Sentence-BERT\n",
        "        similarities = sbert_func(candidatos, referencias)\n",
        "\n",
        "        for idx, sim in enumerate(similarities):\n",
        "            resultados_sbert.append({\n",
        "                'modismo': model_data[idx]['modismo'],\n",
        "                'ejemplo': model_data[idx]['ejemplo'],\n",
        "                'modelo': model,\n",
        "                'sbert_model': sbert_name,\n",
        "                'similarity': float(sim),\n",
        "                'significado_real': referencias[idx],\n",
        "                'literal_generado': model_data[idx].get('literal_generado', ''),\n",
        "                'definicion_generada': candidatos[idx]\n",
        "            })\n",
        "\n",
        "        # Calcular registros faltantes (omitidos por errores)\n",
        "        registros_procesados = len(model_data)\n",
        "        registros_faltantes = GROUNTH_TRUTH - registros_procesados\n",
        "\n",
        "        # Agregar registros faltantes con similarity 0\n",
        "        if registros_faltantes > 0:\n",
        "            print(f\"  ⚠ {registros_faltantes} registros omitidos se cuentan con similarity 0\")\n",
        "            for _ in range(registros_faltantes):\n",
        "                resultados_sbert.append({\n",
        "                    'modismo': 'ERROR/OMITIDO',\n",
        "                    'ejemplo': '',\n",
        "                    'modelo': model,\n",
        "                    'sbert_model': sbert_name,\n",
        "                    'similarity': 0.0,\n",
        "                    'significado_real': '',\n",
        "                    'literal_generado': '',\n",
        "                    'definicion_generada': ''\n",
        "                })\n",
        "\n",
        "        # Calcular promedio sobre el total (GROUNTH_TRUTH)\n",
        "        all_similarities = [r['similarity'] for r in resultados_sbert if r['modelo'] == model and r['sbert_model'] == sbert_name]\n",
        "        sim_mean = np.mean(all_similarities)\n",
        "\n",
        "        print(f\"  • Similitud: {sim_mean:.4f}\")\n",
        "        print(f\"    - Procesados: {registros_procesados}\")\n",
        "        print(f\"    - Errores/omitidos: {registros_faltantes}\")\n",
        "\n",
        "    # Guardar resultados\n",
        "    output_file = os.path.join(OUTPUT_DIR, f'prompt_3_{sbert_name.lower()}_sbert_similarity_resultados.json')\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(resultados_sbert, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print()\n",
        "    print(f\"RESULTADOS con Sentence-BERT ({sbert_name}):\")\n",
        "    for model in MODEL_NAMES:\n",
        "        model_results = [r for r in resultados_sbert if r['modelo'] == model]\n",
        "        if model_results:\n",
        "            similarities = [r['similarity'] for r in model_results]\n",
        "            sim_mean = np.mean(similarities)\n",
        "            sim_std = np.std(similarities)\n",
        "\n",
        "            print(f\"   {model}:\")\n",
        "            print(f\"      • Similitud: {sim_mean:.4f} (±{sim_std:.4f}) [{len(model_results)}/{GROUNTH_TRUTH}]\")\n",
        "\n",
        "    print(f\"\\n✓ Guardado en: {output_file}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 3. chrF Score\n",
        "# ============================================================================\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Calculando chrF Score\")\n",
        "print('='*60)\n",
        "\n",
        "resultados_chrf = []\n",
        "\n",
        "for model in MODEL_NAMES:\n",
        "    print(f\"Evaluando modelo: {model}\")\n",
        "\n",
        "    model_data = [d for d in data_p3_valid if d.get('modelo') == model]\n",
        "\n",
        "    if not model_data:\n",
        "        print(f\"  ⚠ No hay datos para {model} - todos los registros con chrF 0\")\n",
        "        # Agregar todos los registros con chrF 0\n",
        "        for _ in range(GROUNTH_TRUTH):\n",
        "            resultados_chrf.append({\n",
        "                'modismo': 'N/A',\n",
        "                'ejemplo': '',\n",
        "                'modelo': model,\n",
        "                'chrf_score': 0.0,\n",
        "                'significado_real': '',\n",
        "                'literal_generado': '',\n",
        "                'definicion_generada': ''\n",
        "            })\n",
        "        print(f\"  • chrF: 0.0000 (0/{GROUNTH_TRUTH})\")\n",
        "        continue\n",
        "\n",
        "    referencias = [d['significado_real'] for d in model_data]\n",
        "    candidatos = [d['definicion_generada'] for d in model_data]\n",
        "\n",
        "    # Calcular chrF\n",
        "    chrf_scores = compute_chrf_batch(candidatos, referencias)\n",
        "\n",
        "    for idx, score in enumerate(chrf_scores):\n",
        "        resultados_chrf.append({\n",
        "            'modismo': model_data[idx]['modismo'],\n",
        "            'ejemplo': model_data[idx]['ejemplo'],\n",
        "            'modelo': model,\n",
        "            'chrf_score': float(score),\n",
        "            'significado_real': referencias[idx],\n",
        "            'literal_generado': model_data[idx].get('literal_generado', ''),\n",
        "            'definicion_generada': candidatos[idx]\n",
        "        })\n",
        "\n",
        "    # Calcular registros faltantes (omitidos por errores)\n",
        "    registros_procesados = len(model_data)\n",
        "    registros_faltantes = GROUNTH_TRUTH - registros_procesados\n",
        "\n",
        "    # Agregar registros faltantes con chrF 0\n",
        "    if registros_faltantes > 0:\n",
        "        print(f\"  ⚠ {registros_faltantes} registros omitidos se cuentan con chrF 0\")\n",
        "        for _ in range(registros_faltantes):\n",
        "            resultados_chrf.append({\n",
        "                'modismo': 'ERROR/OMITIDO',\n",
        "                'ejemplo': '',\n",
        "                'modelo': model,\n",
        "                'chrf_score': 0.0,\n",
        "                'significado_real': '',\n",
        "                'literal_generado': '',\n",
        "                'definicion_generada': ''\n",
        "            })\n",
        "\n",
        "    # Calcular promedio sobre el total (GROUNTH_TRUTH)\n",
        "    all_chrf_scores = [r['chrf_score'] for r in resultados_chrf if r['modelo'] == model]\n",
        "    chrf_mean = np.mean(all_chrf_scores)\n",
        "\n",
        "    print(f\"  • chrF: {chrf_mean:.4f}\")\n",
        "    print(f\"    - Procesados: {registros_procesados}\")\n",
        "    print(f\"    - Errores/omitidos: {registros_faltantes}\")\n",
        "\n",
        "# Guardar resultados\n",
        "output_file = os.path.join(OUTPUT_DIR, 'prompt_3_chrf_resultados.json')\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(resultados_chrf, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print()\n",
        "print(\"RESULTADOS con chrF:\")\n",
        "for model in MODEL_NAMES:\n",
        "    model_results = [r for r in resultados_chrf if r['modelo'] == model]\n",
        "    if model_results:\n",
        "        chrf_scores = [r['chrf_score'] for r in model_results]\n",
        "        chrf_mean = np.mean(chrf_scores)\n",
        "        chrf_std = np.std(chrf_scores)\n",
        "\n",
        "        print(f\"   {model}:\")\n",
        "        print(f\"      • chrF: {chrf_mean:.4f} (±{chrf_std:.4f}) [{len(model_results)}/{GROUNTH_TRUTH}]\")\n",
        "\n",
        "print(f\"\\n✓ Guardado en: {output_file}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PROMPT 3 COMPLETADO\")\n",
        "print(\"=\"*80 + \"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
